{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Steps to follow\n",
    "\n",
    "1.train a generative adversarial network on a one-dimensional function                             \n",
    "2.define the standalone discriminator model                                   \n",
    "3.define the standalone generator model                                            \n",
    "4.define the combined generator and discriminator model, for updating the generator                    \n",
    "5.generate n real samples with class labels                                               \n",
    "6.generate points in latent space as input for the generator                                      \n",
    "7.use the generator to generate n fake examples, with class labels                                        \n",
    "8.evaluate the discriminator and plot real and fake points                                               \n",
    "9.train the generator and discriminator                   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from matplotlib import pyplot\n",
    "import numpy as np\n",
    "from numpy.random import randn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the standalone discriminator model\n",
    "\n",
    "def discriminator(n_inputs = 2):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(25, activation = 'relu', kernel_initializer='he_uniform',input_dim = n_inputs))\n",
    "    model.add(Dense(1, activation = 'sigmoid'))\n",
    "    model.compile(optimizer = 'adam', loss = 'binary_crossentropy',metrics = ['accuracy'] )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the standalone generator model\n",
    "\n",
    "def generator(latent_dim,n_outputs = 2):\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(15,activation = 'relu',kernel_initializer='he_uniform',input_dim = latent_dim))\n",
    "    model.add(Dense(n_outputs, activation = 'linear'))\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the combined generator and discriminator model, for updating the generator\n",
    "\n",
    "def gan(generator, discriminator):\n",
    "    \n",
    "    discriminator.trainable = False\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(generator)\n",
    "    model.add(discriminator)\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate n real samples with class labels\n",
    "# sample\n",
    "def generate_real(n):\n",
    "    x1 = np.random.rand(n) - 0.5\n",
    "    x2 = x1 * x1\n",
    "    x1 = x1.reshape(n,1)\n",
    "    x2 = x2.reshape(n,1)\n",
    "    x = np.hstack((x1,x2))\n",
    "    y = np.ones((n,1))\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate points in latent space as input for the generator\n",
    "def generate_points(latent_dim , n):\n",
    "    \n",
    "    inputs = randn(latent_dim * n)\n",
    "    inputs = inputs.reshape(n , latent_dim)\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the generator to generate n fake examples, with class labels\n",
    "\n",
    "def generate_fake(generator, latent_dim, n):\n",
    "    \n",
    "    inputs = generate_points(latent_dim, n)\n",
    "    \n",
    "    x = generator.predict(inputs)\n",
    "    y = np.zeros((n,1))\n",
    "    \n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the discriminator and plot real and fake points\n",
    "def evaluate(epoch, generator, discriminator, latent_dim, n=100):\n",
    "    \n",
    "    x_real,y_real = generate_real(n)\n",
    "    _ , acc_real = discriminator.evaluate(x_real,y_real, verbose=0)\n",
    "    \n",
    "    x_fake,y_fake = generate_fake(generator,latent_dim ,n)\n",
    "    _ , acc_fake = discriminator.evaluate(x_fake,y_fake , verbose=0)\n",
    "    \n",
    "    print (epoch, acc_real,acc_fake)\n",
    "    \n",
    "    pyplot.scatter(x_real[:, 0], x_real[:, 1], color='red')\n",
    "    pyplot.scatter(x_fake[:, 0], x_fake[:, 1], color='blue')\n",
    "    # save plot to file\n",
    "    filename = 'generated_plot_e%03d.png' % (epoch+1)\n",
    "    pyplot.savefig(filename)\n",
    "    pyplot.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the generator and discriminator\n",
    "def train(g_model,d_model,gan_model,latent_dim, n_epochs=10000, n_batch=128,n_eval=2000):\n",
    "    \n",
    "    # determine half the size of one batch, for updating the discriminator\n",
    "    half_batch = int(n_batch / 2)\n",
    "# manually enumerate epochs\n",
    "    for i in range(n_epochs):\n",
    "        \n",
    "# prepare real samples\n",
    "        x_real, y_real = generate_real(half_batch)\n",
    "# prepare fake examples\n",
    "        x_fake, y_fake = generate_fake(g_model, latent_dim, half_batch)\n",
    "# update discriminator\n",
    "        d_model.train_on_batch(x_real, y_real)\n",
    "        d_model.train_on_batch(x_fake, y_fake)\n",
    "# prepare points in latent space as input for the generator\n",
    "        x_gan = generate_points(latent_dim,n = n_batch)\n",
    "# create inverted labels for the fake samples\n",
    "        y_gan = np.ones((n_batch, 1))\n",
    "# update the generator via the discriminator's error\n",
    "        gan_model.train_on_batch(x_gan, y_gan)\n",
    "# evaluate the model every n_eval epochs\n",
    "        if (i+1) % n_eval == 0:\n",
    "            evaluate(i, g_model, d_model, latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0601 00:37:48.296775 13164 deprecation.py:323] From C:\\Users\\samya\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "C:\\Users\\samya\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py:297: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1999 0.5299999713897705 0.4399999976158142\n",
      "3999 0.49000000953674316 0.029999999329447746\n",
      "5999 0.5 0.8700000047683716\n",
      "7999 0.3499999940395355 0.7699999809265137\n",
      "9999 0.44999998807907104 0.5799999833106995\n"
     ]
    }
   ],
   "source": [
    "latent_dim = 5\n",
    "# create the discriminator\n",
    "discriminator = discriminator()\n",
    "# create the generator\n",
    "generator = generator(latent_dim)\n",
    "# create the gan\n",
    "gan_model = gan(generator, discriminator)\n",
    "# train model\n",
    "train(generator, discriminator, gan_model, latent_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
