{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import numpy as np\n",
    "from numpy import expand_dims\n",
    "from numpy.random import randint\n",
    "import matplotlib\n",
    "from matplotlib import pyplot\n",
    "from keras.models import Sequential\n",
    "from keras.datasets.mnist import load_data\n",
    "from keras.layers import Conv2D , Conv2DTranspose , Reshape,Flatten,Dense,ReLU,LeakyReLU,Dropout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator():\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Conv2D(64 , (3,3) , strides = (2,2), padding = 'same',input_shape = (28,28,1) ))\n",
    "\tmodel.add(LeakyReLU())\n",
    "\tmodel.add(Dropout(0.3))\n",
    "\n",
    "\tmodel.add(Conv2D(64 , (3,3) , strides = (2,2),padding= 'same' ))\n",
    "\tmodel.add(LeakyReLU())\n",
    "\tmodel.add(Dropout(0.3))\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(1,activation= 'sigmoid'))\n",
    "\tmodel.compile(optimizer= 'adam',loss = 'binary_crossentropy')\n",
    "\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generator(latent_dim = 100):\n",
    "\tmodel =Sequential()\n",
    "\tn_nodes = 128*7*7\n",
    "\tmodel.add(Dense(n_nodes, input_dim = latent_dim))\n",
    "\tmodel.add(ReLU())\n",
    "\t#model.add(Dropout(0.3))\n",
    "\n",
    "\tmodel.add(Reshape((7,7,128) ))\n",
    "\n",
    "\tmodel.add(Conv2DTranspose(128 , (3,3),strides =(2,2), padding= 'same'))\n",
    "\tmodel.add(ReLU())\n",
    "\t#model.add(Dropout(0.3))\n",
    "\n",
    "\t\n",
    "\tmodel.add(Conv2DTranspose(128 , (3,3),strides =(2,2), padding= 'same'))\n",
    "\tmodel.add(ReLU())\n",
    "\t#model.add(Dropout(0.3))\n",
    "\n",
    "\tmodel.add(Conv2D(1,(7,7),activation= 'sigmoid' ,padding = 'same'))\n",
    "\t\n",
    "\treturn model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def gan(g_model ,d_model):\n",
    "\n",
    "\td_model.trainable = False\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(g_model)\n",
    "\tmodel.add(d_model)\n",
    "\n",
    "\tmodel.compile(optimizer= 'adam',loss = 'binary_crossentropy')\n",
    "\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_true_data():\n",
    "\n",
    "\t(x_train, _),(_, _) = load_data() # loading data (28*28)\n",
    "\tx_train = expand_dims(x_train , axis =-1) # adding dim of channel (1)\n",
    "\tx_train = x_train.astype('float32')\n",
    "\n",
    "\tx_train = (x_train - 127.5)/127.5\n",
    "\n",
    "\treturn x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_real_examples(dataset , n_samples):\n",
    "\tindex = randint(0, dataset.shape[0] , n_samples)\n",
    "\tx = dataset[index]\n",
    "\ty = np.ones((n_samples,1))\n",
    "\treturn x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_latent_point(latent_dim , n_samples):\n",
    "\n",
    "\tinputs =np.random.randn(latent_dim * n_samples)\n",
    "\tinputs.reshape(n_samples,latent_dim)\n",
    "\n",
    "\treturn inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_fake_samples(g_model,latent_dim,n_samples):\n",
    "\tx_inp = generate_latent_point(latent_dim, n_samples)\n",
    "\tx = g_model.predict(x_inp)\n",
    "\ty = np.zeros((n_samples,1))\n",
    "\n",
    "\treturn x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def save_plots(examples,epochs,n = 10):\n",
    "\n",
    "\tfor i in range(n * n):\n",
    "\t\tpyplot.subplot(n,n,1+i)\n",
    "\t\tpyplot.axis('off')\n",
    "\t\tpyplot.imshow(examples[i, :, :, 0], cmap='gray_r')\n",
    "\t\tfilename = 'generated_plot_e%03d.png' % (epoch+1)\n",
    "\t\tpyplot.savefig(filename)\n",
    "\t\tpyplot.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_performance(epoch, g_model, d_model, dataset, latent_dim, n_samples = 100):\n",
    "\n",
    "\tx_real,y_real = generate_real_examples(dataset,n_samples)\n",
    "\t_,acc_real = d_model.evaluate(x_real,y_real ,verbose = 0)\n",
    "\n",
    "\tx_fake,y_fake = generate_fake_samples(g_model,latent_dim,n_samples)\n",
    "\t_,acc_fake = d_model.evaluate(x_fake,y_fake ,verbose = 0)\n",
    "\n",
    "\tprint('>Accuracy real: %.0f%%, fake: %.0f%%' % (acc_real*100, acc_fake*100))\n",
    "\tsave_plots(x_fake,epoch)\n",
    "\tfilename = 'generator_model_%03d.h5' % (epoch+1)\n",
    "\tg_model.save(filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(g_model, d_model, gan_model, dataset, latent_dim, n_epochs=100, n_batch=256):\n",
    "\tbatch = int(n_batch/2)\n",
    "\tbatch_per_epoch = int(dataset.shape[0]/n_batch)\n",
    "\n",
    "\tfor i in range (n_epochs):\n",
    "\t\tfor j in range(batch_per_epoch):\n",
    "\n",
    "\t\t\tx_real,y_real = generate_real_examples(dataset,batch)\n",
    "\n",
    "\t\t\tx_fake,y_fake = generate_fake_samples(g_model,latent_dim,batch)\n",
    "\t\t\tx,y = np.vstack((x_real,x_fake)),np.vstack((y_real,y_fake))\n",
    "\n",
    "\t\t\t\n",
    "\t\t\td_loss,_ = d_model.train_on_batch(x,y)\n",
    "\n",
    "\t\t\tx_gan = generate_latent_point(latent_dim,n_batch)\n",
    "\t\t\ty_gan = np.ones((n_batch,1))\n",
    "\n",
    "\t\t\tg_loss = gan_model.train_on_batch(x_gan,y_gan)\n",
    "\t\t\tprint('>%d, %d/%d, d=%.3f, g=%.3f' % (i+1, j+1, bat_per_epo, d_loss, g_loss))\n",
    "\t\t\n",
    "\t\tif (i+1)%10 ==0 :\n",
    "\t\t\tsummarize_performance(i,g_model,d_model,dataset,latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_10 (Conv2D)           (None, 14, 14, 64)        640       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 7, 7, 64)          36928     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 3137      \n",
      "=================================================================\n",
      "Total params: 81,410\n",
      "Trainable params: 40,705\n",
      "Non-trainable params: 40,705\n",
      "_________________________________________________________________\n",
      "_______________________________________________________________________________________________________________\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_8 (Dense)              (None, 6272)              633472    \n",
      "_________________________________________________________________\n",
      "re_lu_10 (ReLU)              (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "reshape_4 (Reshape)          (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_7 (Conv2DTr (None, 14, 14, 128)       147584    \n",
      "_________________________________________________________________\n",
      "re_lu_11 (ReLU)              (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_8 (Conv2DTr (None, 28, 28, 128)       147584    \n",
      "_________________________________________________________________\n",
      "re_lu_12 (ReLU)              (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 28, 28, 1)         6273      \n",
      "=================================================================\n",
      "Total params: 934,913\n",
      "Trainable params: 934,913\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected dense_8_input to have shape (100,) but got array with shape (1,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-f66e6ece48c8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mg_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_true_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg_model\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0md_model\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgan_model\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlatent_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-35-cd15e5556ab0>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(g_model, d_model, gan_model, dataset, latent_dim, n_epochs, n_batch)\u001b[0m\n\u001b[0;32m      8\u001b[0m                         \u001b[0mx_real\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_real\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerate_real_examples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m                         \u001b[0mx_fake\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_fake\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerate_fake_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg_model\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlatent_dim\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m                         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_real\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx_fake\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_real\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_fake\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-32-96a4ada1dacd>\u001b[0m in \u001b[0;36mgenerate_fake_samples\u001b[1;34m(g_model, latent_dim, n_samples)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mgenerate_fake_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg_model\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlatent_dim\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[0mx_inp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerate_latent_point\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlatent_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mg_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_inp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1439\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1440\u001b[0m         \u001b[1;31m# Case 2: Symbolic tensors or Numpy array-like.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1441\u001b[1;33m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_standardize_user_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1442\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1443\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m    577\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    578\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 579\u001b[1;33m             exception_prefix='input')\n\u001b[0m\u001b[0;32m    580\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    581\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    143\u001b[0m                             \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' but got array with shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 145\u001b[1;33m                             str(data_shape))\n\u001b[0m\u001b[0;32m    146\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking input: expected dense_8_input to have shape (100,) but got array with shape (1,)"
     ]
    }
   ],
   "source": [
    "\n",
    "latent_dim = 100\n",
    "d_model = discriminator()\n",
    "g_model =generator(latent_dim)\n",
    "gan_model = gan(g_model,d_model)\n",
    "\n",
    "d_model.summary()\n",
    "print(\"_______________________________________________________________________________________________________________\")\n",
    "g_model.summary()\n",
    "dataset = load_true_data()\n",
    "train(g_model,d_model,gan_model,dataset,latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
