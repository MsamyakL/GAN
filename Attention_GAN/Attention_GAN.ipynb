{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Attention_GAN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJV9y4cqblw6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "6e9313aa-d6fd-4d4b-e2ab-4c243839b2e4"
      },
      "source": [
        "from google.colab import drive\n",
        "ROOT = \"/content/drive\"\n",
        "drive.mount(ROOT)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7JknhzMKpwmD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2a9a4025-1bb3-42b4-a4a1-5b9259a9a383"
      },
      "source": [
        "%cd drive/My\\ Drive/"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UeAiNlLfpwi7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "16816f0b-7231-4b58-ff00-5231dbf4059d"
      },
      "source": [
        "%cd Repo"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Repo\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-syoimAOpwg6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b0fd4529-48aa-4791-8ba4-2ee375bfad8e"
      },
      "source": [
        "cd Attention"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Repo/Attention\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "awQX9HxanS4k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "69f5b0bb-7142-4008-96d6-ffc1bc22eb5c"
      },
      "source": [
        "\n",
        "# Clone github repository setup\n",
        "# import join used to join ROOT path and MY_GOOGLE_DRIVE_PATH\n",
        "from os.path import join  \n",
        "\n",
        "# path to your project on Google Drive\n",
        "MY_GOOGLE_DRIVE_PATH = '//content//drive//My Drive//Repo//Attention' \n",
        "# replace with your Github username \n",
        "GIT_USERNAME = \" Yaha Github Username daal dena apna\" \n",
        "# definitely replace with your\n",
        "GIT_TOKEN = \"{Iske andhar generated token daal dena}\"  \n",
        "# Replace with your github repository in this case we want \n",
        "# to clone deep-learning-v2-pytorch repository\n",
        "GIT_REPOSITORY = \"AttentionGAN\" \n",
        "\n",
        "PROJECT_PATH = join(ROOT, MY_GOOGLE_DRIVE_PATH)\n",
        "\n",
        "# It's good to print out the value if you are not sure \n",
        "print(\"PROJECT_PATH: \", PROJECT_PATH)   \n",
        "\n",
        "# In case we haven't created the folder already; we will create a folder in the project path \n",
        "!mkdir \"{PROJECT_PATH}\"    \n",
        "\n",
        "#GIT_PATH = \"https://{GIT_TOKEN}@github.com/{GIT_USERNAME}/{GIT_REPOSITORY}.git\" this return 400 Bad Request for me\n",
        "GIT_PATH = \"https://\" + GIT_TOKEN + \"@github.com/\" + GIT_USERNAME + \"/\" + GIT_REPOSITORY + \".git\"\n",
        "print(\"GIT_PATH: \", GIT_PATH)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PROJECT_PATH:  //content//drive//My Drive//Repo//Attention\n",
            "mkdir: cannot create directory ‘//content//drive//My Drive//Repo//Attention’: File exists\n",
            "GIT_PATH:  https://{Iske andhar generated token daal dena}@github.com/ Yaha Github Username daal dena apna/AttentionGAN.git\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Avbqs1qSy0T_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# %cd \"{PROJECT_PATH}\"    # Change directory to the location defined in project_path\n",
        "# !git clone \"{GIT_PATH}\" "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vrKXhR-MBcyS",
        "colab_type": "text"
      },
      "source": [
        "Code Starts Here"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PfzBCBZRzdL8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d58d6de2-f469-48f5-abd0-15ab2fbaeb36"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Repo/Attention\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kiR7ZiZUI-Gu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f7eacac3-7cc8-42f9-abef-205f3026a5b9"
      },
      "source": [
        "cd AttentionGAN"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Repo/Attention/AttentionGAN\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6jH-0sRSCMje",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "outputId": "cd683347-3a40-4f65-8494-fa9549604dff"
      },
      "source": [
        "!sh ./datasets/download_cyclegan_dataset.sh \"horse2zebra\"\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "./datasets/download_cyclegan_dataset.sh: 3: ./datasets/download_cyclegan_dataset.sh: [[: not found\n",
            "Specified [horse2zebra]\n",
            "WARNING: timestamping does nothing in combination with -O. See the manual\n",
            "for details.\n",
            "\n",
            "--2020-07-16 10:21:38--  https://people.eecs.berkeley.edu/~taesung_park/CycleGAN/datasets/horse2zebra.zip\n",
            "Resolving people.eecs.berkeley.edu (people.eecs.berkeley.edu)... 128.32.189.73\n",
            "Connecting to people.eecs.berkeley.edu (people.eecs.berkeley.edu)|128.32.189.73|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 116867962 (111M) [application/zip]\n",
            "Saving to: ‘./datasets/horse2zebra.zip’\n",
            "\n",
            "horse2zebra.zip      75%[==============>     ]  84.04M  16.4MB/s    eta 3s     ^C\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "od4_-jDTOAdG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "7daa550c-c5b0-422c-f7e3-41a39dc204cf"
      },
      "source": [
        "pip install dominate"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting dominate\n",
            "  Downloading https://files.pythonhosted.org/packages/4f/e6/794a119963b7cfe4bd41177c8f9d4195fe901652f04189fbd2edf513c7b2/dominate-2.5.1-py2.py3-none-any.whl\n",
            "Installing collected packages: dominate\n",
            "Successfully installed dominate-2.5.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SE9_5uqEOAYz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "outputId": "1db2bb65-3ae6-4c2a-824f-11f11b6d5652"
      },
      "source": [
        "pip install scipy==1.1.0 --user"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting scipy==1.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a8/0b/f163da98d3a01b3e0ef1cab8dd2123c34aee2bafbb1c5bffa354cc8a1730/scipy-1.1.0-cp36-cp36m-manylinux1_x86_64.whl (31.2MB)\n",
            "\u001b[K     |████████████████████████████████| 31.2MB 102kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from scipy==1.1.0) (1.18.5)\n",
            "\u001b[31mERROR: umap-learn 0.4.6 has requirement scipy>=1.3.1, but you'll have scipy 1.1.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.2.0 has requirement scipy==1.4.1; python_version >= \"3\", but you'll have scipy 1.1.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: plotnine 0.6.0 has requirement scipy>=1.2.0, but you'll have scipy 1.1.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: scipy\n",
            "Successfully installed scipy-1.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pq892mSpCrc8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3cb2a821-94b6-45bb-9b73-37c9741a8e58"
      },
      "source": [
        "!sh ./scripts/train_attentiongan.sh"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+ python train.py --dataroot ./datasets/horse2zebra --name horse2zebra_attentiongan --model attention_gan --dataset_mode unaligned --pool_size 50 --no_dropout --norm instance --lambda_A 10 --lambda_B 10 --lambda_identity 0.5 --load_size 286 --crop_size 256 --batch_size 2 --niter 60 --niter_decay 0 --gpu_ids 0 --display_id 0 --display_freq 100 --print_freq 100 --continue_train --epoch_count 8\n",
            "----------------- Options ---------------\n",
            "               batch_size: 2                             \t[default: 1]\n",
            "                    beta1: 0.5                           \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "           continue_train: True                          \t[default: False]\n",
            "                crop_size: 256                           \n",
            "                 dataroot: ./datasets/horse2zebra        \t[default: None]\n",
            "             dataset_mode: unaligned                     \n",
            "                direction: AtoB                          \n",
            "              display_env: main                          \n",
            "             display_freq: 100                           \t[default: 400]\n",
            "               display_id: 0                             \t[default: 1]\n",
            "            display_ncols: 10                            \n",
            "             display_port: 8097                          \n",
            "           display_server: http://localhost              \n",
            "          display_winsize: 256                           \n",
            "                    epoch: latest                        \n",
            "              epoch_count: 8                             \t[default: 1]\n",
            "                 gan_mode: lsgan                         \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: True                          \t[default: None]\n",
            "                 lambda_A: 10.0                          \n",
            "                 lambda_B: 10.0                          \n",
            "          lambda_identity: 0.5                           \n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 286                           \n",
            "                       lr: 0.0002                        \n",
            "           lr_decay_iters: 50                            \n",
            "                lr_policy: linear                        \n",
            "         max_dataset_size: inf                           \n",
            "                    model: attention_gan                 \t[default: cycle_gan]\n",
            "               n_layers_D: 3                             \n",
            "                     name: horse2zebra_attentiongan      \t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: resnet_9blocks                \n",
            "                      ngf: 64                            \n",
            "                    niter: 60                            \t[default: 100]\n",
            "              niter_decay: 0                             \t[default: 100]\n",
            "               no_dropout: True                          \n",
            "                  no_flip: False                         \n",
            "                  no_html: False                         \n",
            "                     norm: instance                      \n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: train                         \n",
            "                pool_size: 50                            \n",
            "               preprocess: resize_and_crop               \n",
            "               print_freq: 100                           \n",
            "                 saveDisk: False                         \n",
            "             save_by_iter: False                         \n",
            "          save_epoch_freq: 5                             \n",
            "         save_latest_freq: 5000                          \n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "         update_html_freq: 1000                          \n",
            "                  verbose: False                         \n",
            "----------------- End -------------------\n",
            "dataset [UnalignedDataset] was created\n",
            "The number of training images = 1334\n",
            "initialize network with normal\n",
            "initialize network with normal\n",
            "initialize network with normal\n",
            "initialize network with normal\n",
            "model [AttentionGANModel] was created\n",
            "loading the model from ./checkpoints/horse2zebra_attentiongan/latest_net_G_A.pth\n",
            "loading the model from ./checkpoints/horse2zebra_attentiongan/latest_net_G_B.pth\n",
            "loading the model from ./checkpoints/horse2zebra_attentiongan/latest_net_D_A.pth\n",
            "loading the model from ./checkpoints/horse2zebra_attentiongan/latest_net_D_B.pth\n",
            "---------- Networks initialized -------------\n",
            "[Network G_A] Total number of parameters : 11.823 M\n",
            "[Network G_B] Total number of parameters : 11.823 M\n",
            "[Network D_A] Total number of parameters : 2.765 M\n",
            "[Network D_B] Total number of parameters : 2.765 M\n",
            "-----------------------------------------------\n",
            "create web directory ./checkpoints/horse2zebra_attentiongan/web...\n",
            "(epoch: 8, iters: 100, time: 1.288, data: 0.246) D_A: 0.070 G_A: 0.552 cycle_A: 0.051 idt_A: 0.000 D_B: 0.222 G_B: 1.047 cycle_B: 0.191 idt_B: 0.002 \n",
            "(epoch: 8, iters: 200, time: 1.321, data: 0.002) D_A: 0.360 G_A: 0.421 cycle_A: 0.011 idt_A: 0.001 D_B: 0.252 G_B: 0.218 cycle_B: 0.022 idt_B: 0.001 \n",
            "(epoch: 8, iters: 300, time: 1.283, data: 0.003) D_A: 0.213 G_A: 0.421 cycle_A: 0.102 idt_A: 0.001 D_B: 0.380 G_B: 0.422 cycle_B: 0.211 idt_B: 0.002 \n",
            "(epoch: 8, iters: 400, time: 1.284, data: 0.003) D_A: 0.277 G_A: 0.725 cycle_A: 0.174 idt_A: 0.001 D_B: 0.133 G_B: 0.741 cycle_B: 0.157 idt_B: 0.001 \n",
            "(epoch: 8, iters: 500, time: 1.331, data: 0.003) D_A: 0.183 G_A: 0.380 cycle_A: 0.099 idt_A: 0.018 D_B: 0.183 G_B: 0.325 cycle_B: 0.349 idt_B: 0.005 \n",
            "(epoch: 8, iters: 600, time: 1.299, data: 0.003) D_A: 0.180 G_A: 1.108 cycle_A: 0.027 idt_A: 0.001 D_B: 0.070 G_B: 0.501 cycle_B: 0.306 idt_B: 0.002 \n",
            "(epoch: 8, iters: 700, time: 1.338, data: 0.003) D_A: 0.301 G_A: 1.182 cycle_A: 0.039 idt_A: 0.005 D_B: 0.147 G_B: 0.401 cycle_B: 0.220 idt_B: 0.001 \n",
            "(epoch: 8, iters: 800, time: 1.428, data: 0.003) D_A: 0.148 G_A: 0.230 cycle_A: 0.188 idt_A: 0.001 D_B: 0.281 G_B: 0.602 cycle_B: 0.344 idt_B: 0.002 \n",
            "(epoch: 8, iters: 900, time: 1.363, data: 0.003) D_A: 0.343 G_A: 0.788 cycle_A: 0.200 idt_A: 0.041 D_B: 0.167 G_B: 0.196 cycle_B: 0.230 idt_B: 0.004 \n",
            "(epoch: 8, iters: 1000, time: 1.368, data: 0.003) D_A: 0.241 G_A: 0.430 cycle_A: 0.077 idt_A: 0.001 D_B: 0.352 G_B: 0.230 cycle_B: 0.090 idt_B: 0.004 \n",
            "(epoch: 8, iters: 1100, time: 1.343, data: 0.003) D_A: 0.222 G_A: 0.350 cycle_A: 0.258 idt_A: 0.001 D_B: 0.403 G_B: 0.150 cycle_B: 0.529 idt_B: 0.005 \n",
            "(epoch: 8, iters: 1200, time: 1.279, data: 0.003) D_A: 0.256 G_A: 0.757 cycle_A: 0.014 idt_A: 0.001 D_B: 0.213 G_B: 0.167 cycle_B: 0.033 idt_B: 0.002 \n",
            "(epoch: 8, iters: 1300, time: 1.276, data: 0.003) D_A: 0.145 G_A: 0.162 cycle_A: 0.144 idt_A: 0.000 D_B: 0.279 G_B: 0.860 cycle_B: 0.235 idt_B: 0.023 \n",
            "End of epoch 8 / 60 \t Time Taken: 474 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 9, iters: 66, time: 1.466, data: 0.003) D_A: 0.219 G_A: 0.419 cycle_A: 0.192 idt_A: 0.005 D_B: 0.236 G_B: 0.573 cycle_B: 0.182 idt_B: 0.005 \n",
            "(epoch: 9, iters: 166, time: 1.455, data: 0.003) D_A: 0.294 G_A: 0.320 cycle_A: 0.055 idt_A: 0.000 D_B: 0.205 G_B: 0.358 cycle_B: 0.580 idt_B: 0.006 \n",
            "(epoch: 9, iters: 266, time: 1.433, data: 0.004) D_A: 0.319 G_A: 0.513 cycle_A: 0.259 idt_A: 0.047 D_B: 0.168 G_B: 0.430 cycle_B: 0.100 idt_B: 0.002 \n",
            "(epoch: 9, iters: 366, time: 1.399, data: 0.003) D_A: 0.261 G_A: 0.376 cycle_A: 0.113 idt_A: 0.000 D_B: 0.183 G_B: 0.200 cycle_B: 0.183 idt_B: 0.000 \n",
            "(epoch: 9, iters: 466, time: 1.448, data: 0.003) D_A: 0.111 G_A: 0.720 cycle_A: 0.179 idt_A: 0.000 D_B: 0.152 G_B: 0.508 cycle_B: 0.673 idt_B: 0.006 \n",
            "(epoch: 9, iters: 566, time: 1.389, data: 0.004) D_A: 0.149 G_A: 0.615 cycle_A: 0.010 idt_A: 0.000 D_B: 0.216 G_B: 0.476 cycle_B: 0.262 idt_B: 0.003 \n",
            "(epoch: 9, iters: 666, time: 1.389, data: 0.003) D_A: 0.155 G_A: 0.212 cycle_A: 0.373 idt_A: 0.020 D_B: 0.255 G_B: 0.491 cycle_B: 0.381 idt_B: 0.004 \n",
            "(epoch: 9, iters: 766, time: 1.421, data: 0.003) D_A: 0.358 G_A: 0.041 cycle_A: 0.140 idt_A: 0.063 D_B: 0.203 G_B: 0.687 cycle_B: 0.243 idt_B: 0.001 \n",
            "(epoch: 9, iters: 866, time: 1.413, data: 0.003) D_A: 0.141 G_A: 0.404 cycle_A: 0.179 idt_A: 0.000 D_B: 0.101 G_B: 0.574 cycle_B: 0.148 idt_B: 0.001 \n",
            "(epoch: 9, iters: 966, time: 1.364, data: 0.003) D_A: 0.108 G_A: 0.805 cycle_A: 0.003 idt_A: 0.000 D_B: 0.176 G_B: 0.363 cycle_B: 0.264 idt_B: 0.001 \n",
            "(epoch: 9, iters: 1066, time: 1.305, data: 0.004) D_A: 0.136 G_A: 0.729 cycle_A: 0.018 idt_A: 0.000 D_B: 0.033 G_B: 0.774 cycle_B: 0.164 idt_B: 0.001 \n",
            "(epoch: 9, iters: 1166, time: 1.338, data: 0.003) D_A: 0.277 G_A: 0.616 cycle_A: 0.323 idt_A: 0.009 D_B: 0.112 G_B: 0.728 cycle_B: 0.017 idt_B: 0.001 \n",
            "(epoch: 9, iters: 1266, time: 1.330, data: 0.003) D_A: 0.198 G_A: 0.223 cycle_A: 0.040 idt_A: 0.000 D_B: 0.287 G_B: 0.211 cycle_B: 0.098 idt_B: 0.020 \n",
            "End of epoch 9 / 60 \t Time Taken: 475 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 10, iters: 32, time: 1.514, data: 0.003) D_A: 0.284 G_A: 0.627 cycle_A: 0.116 idt_A: 0.013 D_B: 0.206 G_B: 0.440 cycle_B: 0.073 idt_B: 0.001 \n",
            "(epoch: 10, iters: 132, time: 1.475, data: 0.003) D_A: 0.130 G_A: 0.460 cycle_A: 0.277 idt_A: 0.000 D_B: 0.267 G_B: 0.650 cycle_B: 0.486 idt_B: 0.003 \n",
            "(epoch: 10, iters: 232, time: 1.536, data: 0.004) D_A: 0.262 G_A: 0.768 cycle_A: 0.225 idt_A: 0.018 D_B: 0.303 G_B: 0.223 cycle_B: 0.273 idt_B: 0.037 \n",
            "(epoch: 10, iters: 332, time: 1.441, data: 0.004) D_A: 0.103 G_A: 0.775 cycle_A: 0.086 idt_A: 0.001 D_B: 0.652 G_B: 0.238 cycle_B: 0.180 idt_B: 0.005 \n",
            "(epoch: 10, iters: 432, time: 1.475, data: 0.003) D_A: 0.098 G_A: 0.575 cycle_A: 0.119 idt_A: 0.000 D_B: 0.113 G_B: 0.370 cycle_B: 0.228 idt_B: 0.001 \n",
            "(epoch: 10, iters: 532, time: 1.450, data: 0.003) D_A: 0.301 G_A: 0.584 cycle_A: 0.111 idt_A: 0.001 D_B: 0.205 G_B: 0.467 cycle_B: 0.020 idt_B: 0.002 \n",
            "(epoch: 10, iters: 632, time: 1.512, data: 0.003) D_A: 0.222 G_A: 0.186 cycle_A: 0.236 idt_A: 0.000 D_B: 0.278 G_B: 1.222 cycle_B: 0.407 idt_B: 0.000 \n",
            "(epoch: 10, iters: 732, time: 1.442, data: 0.003) D_A: 0.306 G_A: 0.676 cycle_A: 0.062 idt_A: 0.002 D_B: 0.258 G_B: 0.269 cycle_B: 0.048 idt_B: 0.001 \n",
            "(epoch: 10, iters: 832, time: 1.343, data: 0.003) D_A: 0.555 G_A: 0.366 cycle_A: 0.058 idt_A: 0.000 D_B: 0.502 G_B: 0.180 cycle_B: 0.071 idt_B: 0.026 \n",
            "(epoch: 10, iters: 932, time: 1.517, data: 0.003) D_A: 0.122 G_A: 0.337 cycle_A: 0.133 idt_A: 0.000 D_B: 0.054 G_B: 0.592 cycle_B: 0.349 idt_B: 0.020 \n",
            "(epoch: 10, iters: 1032, time: 1.511, data: 0.003) D_A: 0.333 G_A: 0.234 cycle_A: 0.239 idt_A: 0.000 D_B: 0.144 G_B: 0.289 cycle_B: 0.248 idt_B: 0.007 \n",
            "(epoch: 10, iters: 1132, time: 1.446, data: 0.003) D_A: 0.173 G_A: 0.173 cycle_A: 0.085 idt_A: 0.000 D_B: 0.086 G_B: 0.399 cycle_B: 0.265 idt_B: 0.001 \n",
            "(epoch: 10, iters: 1232, time: 1.488, data: 0.003) D_A: 0.219 G_A: 0.615 cycle_A: 0.288 idt_A: 0.235 D_B: 0.306 G_B: 0.214 cycle_B: 0.399 idt_B: 0.001 \n",
            "(epoch: 10, iters: 1332, time: 1.460, data: 0.003) D_A: 0.284 G_A: 0.166 cycle_A: 0.066 idt_A: 0.000 D_B: 0.301 G_B: 0.595 cycle_B: 0.140 idt_B: 0.001 \n",
            "saving the model at the end of epoch 10, iters 4002\n",
            "End of epoch 10 / 60 \t Time Taken: 481 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 11, iters: 98, time: 1.577, data: 0.003) D_A: 0.313 G_A: 0.773 cycle_A: 0.086 idt_A: 0.000 D_B: 0.085 G_B: 0.322 cycle_B: 0.061 idt_B: 0.001 \n",
            "(epoch: 11, iters: 198, time: 1.525, data: 0.003) D_A: 0.146 G_A: 0.174 cycle_A: 0.120 idt_A: 0.001 D_B: 0.287 G_B: 0.232 cycle_B: 0.135 idt_B: 0.002 \n",
            "(epoch: 11, iters: 298, time: 1.545, data: 0.003) D_A: 0.285 G_A: 0.107 cycle_A: 0.256 idt_A: 0.002 D_B: 0.193 G_B: 0.704 cycle_B: 0.049 idt_B: 0.004 \n",
            "(epoch: 11, iters: 398, time: 1.568, data: 0.003) D_A: 0.098 G_A: 0.368 cycle_A: 0.098 idt_A: 0.000 D_B: 0.131 G_B: 0.396 cycle_B: 0.439 idt_B: 0.001 \n",
            "(epoch: 11, iters: 498, time: 1.536, data: 0.003) D_A: 0.110 G_A: 0.419 cycle_A: 0.153 idt_A: 0.000 D_B: 0.130 G_B: 0.377 cycle_B: 0.307 idt_B: 0.003 \n",
            "(epoch: 11, iters: 598, time: 1.429, data: 0.003) D_A: 0.402 G_A: 0.290 cycle_A: 0.101 idt_A: 0.001 D_B: 0.228 G_B: 0.655 cycle_B: 0.054 idt_B: 0.001 \n",
            "(epoch: 11, iters: 698, time: 1.423, data: 0.003) D_A: 0.205 G_A: 0.900 cycle_A: 0.028 idt_A: 0.000 D_B: 0.373 G_B: 0.213 cycle_B: 0.312 idt_B: 0.001 \n",
            "(epoch: 11, iters: 798, time: 1.492, data: 0.003) D_A: 0.807 G_A: 0.898 cycle_A: 0.171 idt_A: 0.150 D_B: 0.302 G_B: 0.048 cycle_B: 0.333 idt_B: 0.001 \n",
            "(epoch: 11, iters: 898, time: 1.474, data: 0.003) D_A: 0.193 G_A: 0.214 cycle_A: 0.050 idt_A: 0.000 D_B: 0.207 G_B: 0.414 cycle_B: 0.181 idt_B: 0.001 \n",
            "(epoch: 11, iters: 998, time: 1.446, data: 0.003) D_A: 0.330 G_A: 1.047 cycle_A: 0.214 idt_A: 0.001 D_B: 0.225 G_B: 0.255 cycle_B: 0.214 idt_B: 0.001 \n",
            "saving the latest model (epoch 11, total_iters 5000)\n",
            "(epoch: 11, iters: 1098, time: 1.517, data: 0.002) D_A: 0.142 G_A: 0.317 cycle_A: 0.079 idt_A: 0.000 D_B: 0.146 G_B: 0.247 cycle_B: 0.454 idt_B: 0.001 \n",
            "(epoch: 11, iters: 1198, time: 1.530, data: 0.003) D_A: 0.105 G_A: 0.543 cycle_A: 0.123 idt_A: 0.000 D_B: 0.251 G_B: 0.346 cycle_B: 0.354 idt_B: 0.001 \n",
            "(epoch: 11, iters: 1298, time: 1.518, data: 0.003) D_A: 0.088 G_A: 0.412 cycle_A: 0.212 idt_A: 0.008 D_B: 0.109 G_B: 0.797 cycle_B: 0.171 idt_B: 0.001 \n",
            "End of epoch 11 / 60 \t Time Taken: 478 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 12, iters: 64, time: 1.538, data: 0.003) D_A: 0.152 G_A: 1.036 cycle_A: 0.002 idt_A: 0.000 D_B: 0.112 G_B: 0.043 cycle_B: 0.415 idt_B: 0.000 \n",
            "(epoch: 12, iters: 164, time: 1.540, data: 0.003) D_A: 0.155 G_A: 0.437 cycle_A: 0.123 idt_A: 0.000 D_B: 0.289 G_B: 0.503 cycle_B: 0.390 idt_B: 0.000 \n",
            "(epoch: 12, iters: 264, time: 1.593, data: 0.003) D_A: 0.043 G_A: 0.594 cycle_A: 0.005 idt_A: 0.000 D_B: 0.169 G_B: 0.685 cycle_B: 0.241 idt_B: 0.002 \n",
            "(epoch: 12, iters: 364, time: 1.460, data: 0.003) D_A: 0.278 G_A: 0.283 cycle_A: 0.092 idt_A: 0.042 D_B: 0.343 G_B: 0.251 cycle_B: 0.083 idt_B: 0.001 \n",
            "(epoch: 12, iters: 464, time: 1.452, data: 0.003) D_A: 0.152 G_A: 0.570 cycle_A: 0.007 idt_A: 0.000 D_B: 0.184 G_B: 0.270 cycle_B: 0.165 idt_B: 0.003 \n",
            "(epoch: 12, iters: 564, time: 1.516, data: 0.003) D_A: 0.125 G_A: 0.355 cycle_A: 0.298 idt_A: 0.003 D_B: 0.214 G_B: 0.672 cycle_B: 0.324 idt_B: 0.002 \n",
            "(epoch: 12, iters: 664, time: 1.513, data: 0.003) D_A: 0.091 G_A: 0.842 cycle_A: 0.194 idt_A: 0.000 D_B: 0.162 G_B: 0.380 cycle_B: 0.242 idt_B: 0.001 \n",
            "(epoch: 12, iters: 764, time: 1.504, data: 0.003) D_A: 0.175 G_A: 0.136 cycle_A: 0.180 idt_A: 0.030 D_B: 0.511 G_B: 0.706 cycle_B: 0.182 idt_B: 0.001 \n",
            "(epoch: 12, iters: 864, time: 1.728, data: 0.003) D_A: 0.138 G_A: 0.173 cycle_A: 0.089 idt_A: 0.000 D_B: 0.312 G_B: 0.552 cycle_B: 0.626 idt_B: 0.002 \n",
            "(epoch: 12, iters: 964, time: 1.571, data: 0.003) D_A: 0.093 G_A: 0.429 cycle_A: 0.263 idt_A: 0.001 D_B: 0.231 G_B: 0.259 cycle_B: 0.321 idt_B: 0.003 \n",
            "(epoch: 12, iters: 1064, time: 1.529, data: 0.003) D_A: 0.115 G_A: 0.388 cycle_A: 0.077 idt_A: 0.000 D_B: 0.163 G_B: 0.375 cycle_B: 0.418 idt_B: 0.001 \n",
            "(epoch: 12, iters: 1164, time: 1.603, data: 0.003) D_A: 0.193 G_A: 0.200 cycle_A: 0.214 idt_A: 0.013 D_B: 0.269 G_B: 1.125 cycle_B: 0.330 idt_B: 0.002 \n",
            "(epoch: 12, iters: 1264, time: 1.640, data: 0.003) D_A: 0.253 G_A: 0.464 cycle_A: 0.240 idt_A: 0.000 D_B: 0.091 G_B: 0.417 cycle_B: 0.424 idt_B: 0.002 \n",
            "End of epoch 12 / 60 \t Time Taken: 479 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 13, iters: 30, time: 1.692, data: 0.003) D_A: 0.109 G_A: 0.369 cycle_A: 0.170 idt_A: 0.000 D_B: 0.178 G_B: 0.518 cycle_B: 0.523 idt_B: 0.001 \n",
            "(epoch: 13, iters: 130, time: 1.639, data: 0.003) D_A: 0.240 G_A: 0.166 cycle_A: 0.076 idt_A: 0.000 D_B: 0.344 G_B: 1.046 cycle_B: 0.380 idt_B: 0.007 \n",
            "(epoch: 13, iters: 230, time: 1.621, data: 0.003) D_A: 0.059 G_A: 0.246 cycle_A: 0.169 idt_A: 0.000 D_B: 0.166 G_B: 0.317 cycle_B: 0.432 idt_B: 0.003 \n",
            "(epoch: 13, iters: 330, time: 1.547, data: 0.003) D_A: 0.349 G_A: 0.167 cycle_A: 0.306 idt_A: 0.003 D_B: 0.280 G_B: 0.143 cycle_B: 0.227 idt_B: 0.001 \n",
            "(epoch: 13, iters: 430, time: 1.614, data: 0.003) D_A: 0.226 G_A: 0.362 cycle_A: 0.153 idt_A: 0.002 D_B: 0.315 G_B: 0.592 cycle_B: 0.234 idt_B: 0.002 \n",
            "(epoch: 13, iters: 530, time: 1.591, data: 0.003) D_A: 0.249 G_A: 0.721 cycle_A: 0.041 idt_A: 0.000 D_B: 0.197 G_B: 0.157 cycle_B: 0.213 idt_B: 0.006 \n",
            "(epoch: 13, iters: 630, time: 1.559, data: 0.003) D_A: 0.310 G_A: 0.304 cycle_A: 0.223 idt_A: 0.000 D_B: 0.157 G_B: 0.701 cycle_B: 0.334 idt_B: 0.001 \n",
            "(epoch: 13, iters: 730, time: 1.563, data: 0.003) D_A: 0.091 G_A: 0.359 cycle_A: 0.103 idt_A: 0.000 D_B: 0.281 G_B: 0.247 cycle_B: 0.319 idt_B: 0.001 \n",
            "(epoch: 13, iters: 830, time: 1.554, data: 0.003) D_A: 0.155 G_A: 0.745 cycle_A: 0.167 idt_A: 0.000 D_B: 0.096 G_B: 0.359 cycle_B: 0.366 idt_B: 0.001 \n",
            "(epoch: 13, iters: 930, time: 1.507, data: 0.003) D_A: 0.209 G_A: 0.479 cycle_A: 0.036 idt_A: 0.003 D_B: 0.276 G_B: 0.297 cycle_B: 0.104 idt_B: 0.000 \n",
            "(epoch: 13, iters: 1030, time: 1.552, data: 0.003) D_A: 0.206 G_A: 1.115 cycle_A: 0.129 idt_A: 0.000 D_B: 0.131 G_B: 0.361 cycle_B: 0.490 idt_B: 0.012 \n",
            "(epoch: 13, iters: 1130, time: 1.625, data: 0.004) D_A: 0.116 G_A: 0.226 cycle_A: 0.298 idt_A: 0.000 D_B: 0.289 G_B: 0.344 cycle_B: 0.547 idt_B: 0.007 \n",
            "(epoch: 13, iters: 1230, time: 1.637, data: 0.003) D_A: 0.259 G_A: 0.212 cycle_A: 0.099 idt_A: 0.000 D_B: 0.387 G_B: 0.090 cycle_B: 0.225 idt_B: 0.002 \n",
            "(epoch: 13, iters: 1330, time: 1.531, data: 0.003) D_A: 0.131 G_A: 0.505 cycle_A: 0.166 idt_A: 0.000 D_B: 0.346 G_B: 0.274 cycle_B: 0.279 idt_B: 0.005 \n",
            "End of epoch 13 / 60 \t Time Taken: 482 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 14, iters: 96, time: 1.673, data: 0.003) D_A: 0.304 G_A: 0.126 cycle_A: 0.246 idt_A: 0.121 D_B: 0.136 G_B: 0.770 cycle_B: 0.086 idt_B: 0.001 \n",
            "(epoch: 14, iters: 196, time: 1.663, data: 0.003) D_A: 0.070 G_A: 0.414 cycle_A: 0.153 idt_A: 0.000 D_B: 0.213 G_B: 0.651 cycle_B: 0.377 idt_B: 0.005 \n",
            "(epoch: 14, iters: 296, time: 1.569, data: 0.003) D_A: 0.164 G_A: 0.594 cycle_A: 0.254 idt_A: 0.011 D_B: 0.187 G_B: 0.162 cycle_B: 0.424 idt_B: 0.008 \n",
            "(epoch: 14, iters: 396, time: 1.722, data: 0.003) D_A: 0.327 G_A: 0.369 cycle_A: 0.163 idt_A: 0.002 D_B: 0.304 G_B: 0.257 cycle_B: 0.178 idt_B: 0.003 \n",
            "(epoch: 14, iters: 496, time: 1.639, data: 0.003) D_A: 0.182 G_A: 0.736 cycle_A: 0.151 idt_A: 0.000 D_B: 0.286 G_B: 0.228 cycle_B: 0.211 idt_B: 0.012 \n",
            "(epoch: 14, iters: 596, time: 1.581, data: 0.003) D_A: 0.235 G_A: 0.272 cycle_A: 0.104 idt_A: 0.000 D_B: 0.169 G_B: 0.412 cycle_B: 0.188 idt_B: 0.000 \n",
            "(epoch: 14, iters: 696, time: 1.606, data: 0.003) D_A: 0.092 G_A: 0.886 cycle_A: 0.007 idt_A: 0.000 D_B: 0.200 G_B: 0.290 cycle_B: 0.495 idt_B: 0.001 \n",
            "(epoch: 14, iters: 796, time: 1.656, data: 0.003) D_A: 0.205 G_A: 0.194 cycle_A: 0.023 idt_A: 0.000 D_B: 0.444 G_B: 0.511 cycle_B: 0.574 idt_B: 0.008 \n",
            "(epoch: 14, iters: 896, time: 1.504, data: 0.003) D_A: 0.042 G_A: 0.475 cycle_A: 0.092 idt_A: 0.000 D_B: 0.180 G_B: 0.759 cycle_B: 0.130 idt_B: 0.001 \n",
            "(epoch: 14, iters: 996, time: 1.648, data: 0.003) D_A: 0.118 G_A: 0.441 cycle_A: 0.148 idt_A: 0.000 D_B: 0.210 G_B: 0.150 cycle_B: 0.397 idt_B: 0.001 \n",
            "(epoch: 14, iters: 1096, time: 1.653, data: 0.003) D_A: 0.336 G_A: 0.399 cycle_A: 0.210 idt_A: 0.007 D_B: 0.389 G_B: 0.492 cycle_B: 0.309 idt_B: 0.001 \n",
            "(epoch: 14, iters: 1196, time: 1.662, data: 0.003) D_A: 0.160 G_A: 0.302 cycle_A: 0.207 idt_A: 0.003 D_B: 0.186 G_B: 0.360 cycle_B: 0.137 idt_B: 0.000 \n",
            "(epoch: 14, iters: 1296, time: 1.564, data: 0.004) D_A: 0.192 G_A: 0.830 cycle_A: 0.178 idt_A: 0.000 D_B: 0.380 G_B: 0.106 cycle_B: 0.363 idt_B: 0.002 \n",
            "End of epoch 14 / 60 \t Time Taken: 481 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 15, iters: 62, time: 1.772, data: 0.003) D_A: 0.051 G_A: 0.665 cycle_A: 0.053 idt_A: 0.000 D_B: 0.359 G_B: 0.134 cycle_B: 0.431 idt_B: 0.000 \n",
            "(epoch: 15, iters: 162, time: 1.749, data: 0.003) D_A: 0.113 G_A: 0.557 cycle_A: 0.210 idt_A: 0.000 D_B: 0.115 G_B: 0.270 cycle_B: 0.679 idt_B: 0.001 \n",
            "(epoch: 15, iters: 262, time: 1.675, data: 0.003) D_A: 0.101 G_A: 0.922 cycle_A: 0.128 idt_A: 0.000 D_B: 0.063 G_B: 0.892 cycle_B: 0.266 idt_B: 0.000 \n",
            "(epoch: 15, iters: 362, time: 1.604, data: 0.003) D_A: 0.166 G_A: 0.547 cycle_A: 0.202 idt_A: 0.003 D_B: 0.224 G_B: 0.287 cycle_B: 0.157 idt_B: 0.001 \n",
            "(epoch: 15, iters: 462, time: 1.567, data: 0.003) D_A: 0.427 G_A: 0.112 cycle_A: 0.104 idt_A: 0.001 D_B: 0.120 G_B: 0.381 cycle_B: 0.293 idt_B: 0.000 \n",
            "(epoch: 15, iters: 562, time: 1.659, data: 0.003) D_A: 0.184 G_A: 0.466 cycle_A: 0.085 idt_A: 0.006 D_B: 0.193 G_B: 0.434 cycle_B: 0.262 idt_B: 0.004 \n",
            "(epoch: 15, iters: 662, time: 1.620, data: 0.003) D_A: 0.187 G_A: 0.460 cycle_A: 0.058 idt_A: 0.000 D_B: 0.198 G_B: 0.299 cycle_B: 0.180 idt_B: 0.000 \n",
            "saving the latest model (epoch 15, total_iters 10000)\n",
            "(epoch: 15, iters: 762, time: 1.658, data: 0.002) D_A: 0.060 G_A: 0.906 cycle_A: 0.153 idt_A: 0.000 D_B: 0.120 G_B: 0.459 cycle_B: 0.447 idt_B: 0.002 \n",
            "(epoch: 15, iters: 862, time: 1.656, data: 0.003) D_A: 0.160 G_A: 0.547 cycle_A: 0.011 idt_A: 0.000 D_B: 0.260 G_B: 0.908 cycle_B: 0.104 idt_B: 0.000 \n",
            "(epoch: 15, iters: 962, time: 1.609, data: 0.003) D_A: 0.257 G_A: 0.131 cycle_A: 0.048 idt_A: 0.000 D_B: 0.299 G_B: 0.676 cycle_B: 0.143 idt_B: 0.009 \n",
            "(epoch: 15, iters: 1062, time: 1.669, data: 0.003) D_A: 0.178 G_A: 0.236 cycle_A: 0.060 idt_A: 0.000 D_B: 0.184 G_B: 0.247 cycle_B: 0.281 idt_B: 0.001 \n",
            "(epoch: 15, iters: 1162, time: 1.659, data: 0.003) D_A: 0.200 G_A: 0.971 cycle_A: 0.078 idt_A: 0.000 D_B: 0.185 G_B: 0.367 cycle_B: 0.265 idt_B: 0.000 \n",
            "(epoch: 15, iters: 1262, time: 1.735, data: 0.003) D_A: 0.259 G_A: 0.370 cycle_A: 0.221 idt_A: 0.000 D_B: 0.257 G_B: 0.148 cycle_B: 0.270 idt_B: 0.001 \n",
            "saving the model at the end of epoch 15, iters 10672\n",
            "End of epoch 15 / 60 \t Time Taken: 486 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 16, iters: 28, time: 1.832, data: 0.003) D_A: 0.122 G_A: 0.606 cycle_A: 0.168 idt_A: 0.008 D_B: 0.245 G_B: 0.249 cycle_B: 0.135 idt_B: 0.001 \n",
            "(epoch: 16, iters: 128, time: 1.765, data: 0.003) D_A: 0.131 G_A: 0.936 cycle_A: 0.193 idt_A: 0.000 D_B: 0.104 G_B: 0.522 cycle_B: 0.449 idt_B: 0.000 \n",
            "(epoch: 16, iters: 228, time: 1.722, data: 0.003) D_A: 0.125 G_A: 0.368 cycle_A: 0.179 idt_A: 0.000 D_B: 0.238 G_B: 0.536 cycle_B: 0.418 idt_B: 0.000 \n",
            "(epoch: 16, iters: 328, time: 1.679, data: 0.003) D_A: 0.125 G_A: 0.525 cycle_A: 0.059 idt_A: 0.011 D_B: 0.160 G_B: 0.954 cycle_B: 0.068 idt_B: 0.001 \n",
            "(epoch: 16, iters: 428, time: 1.770, data: 0.003) D_A: 0.066 G_A: 0.601 cycle_A: 0.093 idt_A: 0.000 D_B: 0.121 G_B: 0.428 cycle_B: 0.435 idt_B: 0.000 \n",
            "(epoch: 16, iters: 528, time: 1.650, data: 0.003) D_A: 0.266 G_A: 0.726 cycle_A: 0.094 idt_A: 0.000 D_B: 0.267 G_B: 0.255 cycle_B: 0.145 idt_B: 0.002 \n",
            "(epoch: 16, iters: 628, time: 1.688, data: 0.003) D_A: 0.137 G_A: 0.581 cycle_A: 0.018 idt_A: 0.000 D_B: 0.263 G_B: 0.227 cycle_B: 0.433 idt_B: 0.000 \n",
            "(epoch: 16, iters: 728, time: 1.643, data: 0.003) D_A: 0.163 G_A: 0.311 cycle_A: 0.169 idt_A: 0.000 D_B: 0.355 G_B: 0.632 cycle_B: 0.256 idt_B: 0.000 \n",
            "(epoch: 16, iters: 828, time: 1.873, data: 0.003) D_A: 0.114 G_A: 0.343 cycle_A: 0.087 idt_A: 0.000 D_B: 0.191 G_B: 0.540 cycle_B: 0.498 idt_B: 0.000 \n",
            "(epoch: 16, iters: 928, time: 1.573, data: 0.003) D_A: 0.318 G_A: 0.743 cycle_A: 0.148 idt_A: 0.000 D_B: 0.255 G_B: 0.270 cycle_B: 0.256 idt_B: 0.000 \n",
            "(epoch: 16, iters: 1028, time: 1.739, data: 0.003) D_A: 0.219 G_A: 1.289 cycle_A: 0.152 idt_A: 0.000 D_B: 0.053 G_B: 0.773 cycle_B: 0.227 idt_B: 0.000 \n",
            "(epoch: 16, iters: 1128, time: 1.667, data: 0.003) D_A: 0.085 G_A: 0.492 cycle_A: 0.177 idt_A: 0.000 D_B: 0.229 G_B: 0.225 cycle_B: 0.357 idt_B: 0.000 \n",
            "(epoch: 16, iters: 1228, time: 1.684, data: 0.003) D_A: 0.105 G_A: 0.514 cycle_A: 0.141 idt_A: 0.000 D_B: 0.223 G_B: 0.762 cycle_B: 0.472 idt_B: 0.001 \n",
            "(epoch: 16, iters: 1328, time: 1.722, data: 0.003) D_A: 0.157 G_A: 0.824 cycle_A: 0.162 idt_A: 0.001 D_B: 0.132 G_B: 0.381 cycle_B: 0.500 idt_B: 0.001 \n",
            "End of epoch 16 / 60 \t Time Taken: 485 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 17, iters: 94, time: 1.798, data: 0.003) D_A: 0.207 G_A: 0.343 cycle_A: 0.049 idt_A: 0.000 D_B: 0.246 G_B: 0.579 cycle_B: 0.270 idt_B: 0.035 \n",
            "(epoch: 17, iters: 194, time: 1.786, data: 0.003) D_A: 0.264 G_A: 0.569 cycle_A: 0.005 idt_A: 0.000 D_B: 0.280 G_B: 0.176 cycle_B: 0.013 idt_B: 0.000 \n",
            "(epoch: 17, iters: 294, time: 1.654, data: 0.003) D_A: 0.217 G_A: 1.288 cycle_A: 0.071 idt_A: 0.000 D_B: 0.083 G_B: 0.248 cycle_B: 0.217 idt_B: 0.000 \n",
            "(epoch: 17, iters: 394, time: 1.732, data: 0.003) D_A: 0.413 G_A: 0.919 cycle_A: 0.332 idt_A: 0.017 D_B: 0.205 G_B: 0.478 cycle_B: 0.194 idt_B: 0.001 \n",
            "(epoch: 17, iters: 494, time: 1.810, data: 0.003) D_A: 0.124 G_A: 0.221 cycle_A: 0.156 idt_A: 0.095 D_B: 0.224 G_B: 1.081 cycle_B: 0.249 idt_B: 0.005 \n",
            "(epoch: 17, iters: 594, time: 1.807, data: 0.003) D_A: 0.298 G_A: 0.863 cycle_A: 0.143 idt_A: 0.000 D_B: 0.157 G_B: 0.163 cycle_B: 0.177 idt_B: 0.001 \n",
            "(epoch: 17, iters: 694, time: 1.848, data: 0.003) D_A: 0.155 G_A: 0.395 cycle_A: 0.192 idt_A: 0.000 D_B: 0.273 G_B: 0.358 cycle_B: 0.360 idt_B: 0.001 \n",
            "(epoch: 17, iters: 794, time: 1.774, data: 0.003) D_A: 0.185 G_A: 0.529 cycle_A: 0.126 idt_A: 0.000 D_B: 0.217 G_B: 0.584 cycle_B: 0.270 idt_B: 0.001 \n",
            "(epoch: 17, iters: 894, time: 1.775, data: 0.003) D_A: 0.221 G_A: 0.861 cycle_A: 0.081 idt_A: 0.001 D_B: 0.101 G_B: 0.344 cycle_B: 0.086 idt_B: 0.000 \n",
            "(epoch: 17, iters: 994, time: 1.717, data: 0.003) D_A: 0.221 G_A: 0.937 cycle_A: 0.015 idt_A: 0.000 D_B: 0.087 G_B: 0.390 cycle_B: 0.179 idt_B: 0.001 \n",
            "(epoch: 17, iters: 1094, time: 1.722, data: 0.003) D_A: 0.213 G_A: 0.483 cycle_A: 0.245 idt_A: 0.002 D_B: 0.158 G_B: 0.560 cycle_B: 0.227 idt_B: 0.000 \n",
            "(epoch: 17, iters: 1194, time: 1.759, data: 0.003) D_A: 0.043 G_A: 0.721 cycle_A: 0.111 idt_A: 0.000 D_B: 0.136 G_B: 0.393 cycle_B: 0.552 idt_B: 0.001 \n",
            "(epoch: 17, iters: 1294, time: 1.784, data: 0.003) D_A: 0.292 G_A: 0.582 cycle_A: 0.219 idt_A: 0.001 D_B: 0.187 G_B: 0.221 cycle_B: 0.295 idt_B: 0.001 \n",
            "End of epoch 17 / 60 \t Time Taken: 484 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 18, iters: 60, time: 1.736, data: 0.003) D_A: 0.209 G_A: 0.683 cycle_A: 0.040 idt_A: 0.000 D_B: 0.306 G_B: 0.194 cycle_B: 0.209 idt_B: 0.003 \n",
            "(epoch: 18, iters: 160, time: 1.750, data: 0.003) D_A: 0.129 G_A: 0.541 cycle_A: 0.197 idt_A: 0.019 D_B: 0.151 G_B: 0.406 cycle_B: 0.242 idt_B: 0.000 \n",
            "(epoch: 18, iters: 260, time: 1.800, data: 0.003) D_A: 0.223 G_A: 0.461 cycle_A: 0.017 idt_A: 0.000 D_B: 0.316 G_B: 0.168 cycle_B: 0.304 idt_B: 0.000 \n",
            "(epoch: 18, iters: 360, time: 1.808, data: 0.003) D_A: 0.228 G_A: 0.469 cycle_A: 0.084 idt_A: 0.000 D_B: 0.297 G_B: 0.294 cycle_B: 0.279 idt_B: 0.003 \n",
            "(epoch: 18, iters: 460, time: 1.809, data: 0.003) D_A: 0.197 G_A: 0.232 cycle_A: 0.152 idt_A: 0.000 D_B: 0.226 G_B: 0.116 cycle_B: 0.363 idt_B: 0.000 \n",
            "(epoch: 18, iters: 560, time: 1.796, data: 0.004) D_A: 0.090 G_A: 0.193 cycle_A: 0.230 idt_A: 0.001 D_B: 0.387 G_B: 0.520 cycle_B: 0.201 idt_B: 0.003 \n",
            "(epoch: 18, iters: 660, time: 1.676, data: 0.003) D_A: 0.244 G_A: 0.693 cycle_A: 0.103 idt_A: 0.000 D_B: 0.096 G_B: 0.428 cycle_B: 0.064 idt_B: 0.000 \n",
            "(epoch: 18, iters: 760, time: 1.737, data: 0.003) D_A: 0.143 G_A: 0.148 cycle_A: 0.422 idt_A: 0.000 D_B: 0.192 G_B: 0.366 cycle_B: 0.284 idt_B: 0.000 \n",
            "(epoch: 18, iters: 860, time: 1.725, data: 0.003) D_A: 0.242 G_A: 0.367 cycle_A: 0.197 idt_A: 0.001 D_B: 0.131 G_B: 0.171 cycle_B: 0.029 idt_B: 0.000 \n",
            "(epoch: 18, iters: 960, time: 1.766, data: 0.003) D_A: 0.260 G_A: 0.479 cycle_A: 0.202 idt_A: 0.000 D_B: 0.256 G_B: 0.340 cycle_B: 0.259 idt_B: 0.001 \n",
            "(epoch: 18, iters: 1060, time: 1.850, data: 0.003) D_A: 0.086 G_A: 0.636 cycle_A: 0.084 idt_A: 0.004 D_B: 0.222 G_B: 0.237 cycle_B: 0.481 idt_B: 0.000 \n",
            "(epoch: 18, iters: 1160, time: 1.728, data: 0.004) D_A: 0.361 G_A: 0.030 cycle_A: 0.270 idt_A: 0.000 D_B: 0.282 G_B: 0.461 cycle_B: 0.249 idt_B: 0.000 \n",
            "(epoch: 18, iters: 1260, time: 1.920, data: 0.003) D_A: 0.108 G_A: 0.825 cycle_A: 0.241 idt_A: 0.000 D_B: 0.086 G_B: 0.512 cycle_B: 0.317 idt_B: 0.000 \n",
            "End of epoch 18 / 60 \t Time Taken: 484 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 19, iters: 26, time: 1.845, data: 0.003) D_A: 0.141 G_A: 1.016 cycle_A: 0.121 idt_A: 0.000 D_B: 0.359 G_B: 0.259 cycle_B: 0.322 idt_B: 0.000 \n",
            "(epoch: 19, iters: 126, time: 1.774, data: 0.003) D_A: 0.307 G_A: 0.336 cycle_A: 0.088 idt_A: 0.000 D_B: 0.137 G_B: 0.381 cycle_B: 0.311 idt_B: 0.000 \n",
            "(epoch: 19, iters: 226, time: 1.765, data: 0.003) D_A: 0.318 G_A: 0.739 cycle_A: 0.197 idt_A: 0.000 D_B: 0.198 G_B: 0.321 cycle_B: 0.132 idt_B: 0.000 \n",
            "(epoch: 19, iters: 326, time: 1.904, data: 0.003) D_A: 0.165 G_A: 0.244 cycle_A: 0.045 idt_A: 0.000 D_B: 0.290 G_B: 0.622 cycle_B: 0.492 idt_B: 0.001 \n",
            "saving the latest model (epoch 19, total_iters 15000)\n",
            "(epoch: 19, iters: 426, time: 1.783, data: 0.005) D_A: 0.247 G_A: 0.603 cycle_A: 0.059 idt_A: 0.003 D_B: 0.141 G_B: 0.348 cycle_B: 0.160 idt_B: 0.001 \n",
            "(epoch: 19, iters: 526, time: 1.748, data: 0.004) D_A: 0.247 G_A: 0.186 cycle_A: 0.169 idt_A: 0.000 D_B: 0.309 G_B: 0.232 cycle_B: 0.205 idt_B: 0.001 \n",
            "(epoch: 19, iters: 626, time: 1.851, data: 0.003) D_A: 0.047 G_A: 0.772 cycle_A: 0.068 idt_A: 0.001 D_B: 0.197 G_B: 0.475 cycle_B: 0.393 idt_B: 0.001 \n",
            "(epoch: 19, iters: 726, time: 1.783, data: 0.003) D_A: 0.255 G_A: 0.146 cycle_A: 0.140 idt_A: 0.013 D_B: 0.183 G_B: 0.561 cycle_B: 0.274 idt_B: 0.001 \n",
            "(epoch: 19, iters: 826, time: 1.789, data: 0.003) D_A: 0.132 G_A: 0.513 cycle_A: 0.005 idt_A: 0.000 D_B: 0.125 G_B: 0.303 cycle_B: 0.283 idt_B: 0.000 \n",
            "(epoch: 19, iters: 926, time: 1.781, data: 0.003) D_A: 0.329 G_A: 0.462 cycle_A: 0.095 idt_A: 0.000 D_B: 0.174 G_B: 0.359 cycle_B: 0.084 idt_B: 0.000 \n",
            "(epoch: 19, iters: 1026, time: 1.760, data: 0.003) D_A: 0.119 G_A: 0.322 cycle_A: 0.127 idt_A: 0.000 D_B: 0.204 G_B: 0.928 cycle_B: 0.031 idt_B: 0.000 \n",
            "(epoch: 19, iters: 1126, time: 1.751, data: 0.003) D_A: 0.164 G_A: 0.457 cycle_A: 0.007 idt_A: 0.001 D_B: 0.149 G_B: 0.698 cycle_B: 0.126 idt_B: 0.000 \n",
            "(epoch: 19, iters: 1226, time: 1.871, data: 0.003) D_A: 0.102 G_A: 0.321 cycle_A: 0.037 idt_A: 0.000 D_B: 0.188 G_B: 0.451 cycle_B: 0.294 idt_B: 0.013 \n",
            "(epoch: 19, iters: 1326, time: 1.837, data: 0.003) D_A: 0.198 G_A: 0.399 cycle_A: 0.324 idt_A: 0.000 D_B: 0.195 G_B: 0.113 cycle_B: 0.263 idt_B: 0.001 \n",
            "End of epoch 19 / 60 \t Time Taken: 490 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 20, iters: 92, time: 1.939, data: 0.003) D_A: 0.206 G_A: 0.134 cycle_A: 0.148 idt_A: 0.000 D_B: 0.340 G_B: 0.991 cycle_B: 0.222 idt_B: 0.001 \n",
            "(epoch: 20, iters: 192, time: 1.888, data: 0.003) D_A: 0.118 G_A: 1.056 cycle_A: 0.008 idt_A: 0.000 D_B: 0.090 G_B: 0.397 cycle_B: 0.377 idt_B: 0.000 \n",
            "(epoch: 20, iters: 292, time: 1.840, data: 0.003) D_A: 0.216 G_A: 0.339 cycle_A: 0.288 idt_A: 0.000 D_B: 0.340 G_B: 0.348 cycle_B: 0.226 idt_B: 0.017 \n",
            "(epoch: 20, iters: 392, time: 1.787, data: 0.003) D_A: 0.331 G_A: 0.496 cycle_A: 0.195 idt_A: 0.055 D_B: 0.189 G_B: 0.339 cycle_B: 0.110 idt_B: 0.001 \n",
            "(epoch: 20, iters: 492, time: 1.888, data: 0.003) D_A: 0.126 G_A: 0.185 cycle_A: 0.311 idt_A: 0.000 D_B: 0.190 G_B: 0.489 cycle_B: 0.176 idt_B: 0.000 \n",
            "(epoch: 20, iters: 592, time: 1.825, data: 0.003) D_A: 0.110 G_A: 0.384 cycle_A: 0.056 idt_A: 0.000 D_B: 0.266 G_B: 0.260 cycle_B: 0.201 idt_B: 0.002 \n",
            "(epoch: 20, iters: 692, time: 1.886, data: 0.003) D_A: 0.157 G_A: 0.308 cycle_A: 0.169 idt_A: 0.000 D_B: 0.184 G_B: 0.388 cycle_B: 0.494 idt_B: 0.001 \n",
            "(epoch: 20, iters: 792, time: 1.840, data: 0.003) D_A: 0.259 G_A: 0.856 cycle_A: 0.132 idt_A: 0.001 D_B: 0.088 G_B: 0.538 cycle_B: 0.175 idt_B: 0.000 \n",
            "(epoch: 20, iters: 892, time: 1.858, data: 0.003) D_A: 0.124 G_A: 0.502 cycle_A: 0.121 idt_A: 0.000 D_B: 0.134 G_B: 0.573 cycle_B: 0.328 idt_B: 0.000 \n",
            "(epoch: 20, iters: 992, time: 1.843, data: 0.004) D_A: 0.097 G_A: 0.354 cycle_A: 0.029 idt_A: 0.000 D_B: 0.288 G_B: 0.510 cycle_B: 0.481 idt_B: 0.009 \n",
            "(epoch: 20, iters: 1092, time: 1.918, data: 0.003) D_A: 0.141 G_A: 0.313 cycle_A: 0.124 idt_A: 0.000 D_B: 0.240 G_B: 0.414 cycle_B: 0.333 idt_B: 0.008 \n",
            "(epoch: 20, iters: 1192, time: 1.755, data: 0.003) D_A: 0.275 G_A: 0.606 cycle_A: 0.130 idt_A: 0.000 D_B: 0.158 G_B: 0.308 cycle_B: 0.047 idt_B: 0.000 \n",
            "(epoch: 20, iters: 1292, time: 1.820, data: 0.003) D_A: 0.103 G_A: 1.006 cycle_A: 0.155 idt_A: 0.000 D_B: 0.250 G_B: 0.265 cycle_B: 0.387 idt_B: 0.000 \n",
            "saving the model at the end of epoch 20, iters 17342\n",
            "End of epoch 20 / 60 \t Time Taken: 488 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 21, iters: 58, time: 1.961, data: 0.003) D_A: 0.063 G_A: 0.640 cycle_A: 0.165 idt_A: 0.002 D_B: 0.277 G_B: 0.091 cycle_B: 0.327 idt_B: 0.000 \n",
            "(epoch: 21, iters: 158, time: 1.925, data: 0.003) D_A: 0.243 G_A: 0.133 cycle_A: 0.235 idt_A: 0.000 D_B: 0.219 G_B: 0.313 cycle_B: 0.249 idt_B: 0.000 \n",
            "(epoch: 21, iters: 258, time: 1.896, data: 0.003) D_A: 0.166 G_A: 0.594 cycle_A: 0.133 idt_A: 0.000 D_B: 0.130 G_B: 0.167 cycle_B: 0.400 idt_B: 0.002 \n",
            "(epoch: 21, iters: 358, time: 1.890, data: 0.003) D_A: 0.235 G_A: 0.514 cycle_A: 0.137 idt_A: 0.000 D_B: 0.210 G_B: 0.269 cycle_B: 0.236 idt_B: 0.000 \n",
            "(epoch: 21, iters: 458, time: 1.879, data: 0.003) D_A: 0.108 G_A: 0.226 cycle_A: 0.237 idt_A: 0.001 D_B: 0.520 G_B: 1.015 cycle_B: 0.258 idt_B: 0.001 \n",
            "(epoch: 21, iters: 558, time: 1.844, data: 0.003) D_A: 0.287 G_A: 0.158 cycle_A: 0.225 idt_A: 0.000 D_B: 0.333 G_B: 0.647 cycle_B: 0.266 idt_B: 0.001 \n",
            "(epoch: 21, iters: 658, time: 1.905, data: 0.003) D_A: 0.139 G_A: 0.357 cycle_A: 0.070 idt_A: 0.000 D_B: 0.143 G_B: 0.433 cycle_B: 0.358 idt_B: 0.001 \n",
            "(epoch: 21, iters: 758, time: 1.796, data: 0.003) D_A: 0.217 G_A: 0.182 cycle_A: 0.178 idt_A: 0.000 D_B: 0.161 G_B: 0.114 cycle_B: 0.101 idt_B: 0.000 \n",
            "(epoch: 21, iters: 858, time: 1.894, data: 0.003) D_A: 0.186 G_A: 0.252 cycle_A: 0.322 idt_A: 0.000 D_B: 0.158 G_B: 0.381 cycle_B: 0.166 idt_B: 0.001 \n",
            "(epoch: 21, iters: 958, time: 1.990, data: 0.003) D_A: 0.197 G_A: 0.433 cycle_A: 0.227 idt_A: 0.049 D_B: 0.246 G_B: 0.589 cycle_B: 0.241 idt_B: 0.000 \n",
            "(epoch: 21, iters: 1058, time: 1.785, data: 0.006) D_A: 0.214 G_A: 1.017 cycle_A: 0.043 idt_A: 0.000 D_B: 0.117 G_B: 0.768 cycle_B: 0.258 idt_B: 0.000 \n",
            "(epoch: 21, iters: 1158, time: 1.912, data: 0.003) D_A: 0.103 G_A: 0.407 cycle_A: 0.138 idt_A: 0.000 D_B: 0.263 G_B: 0.232 cycle_B: 0.468 idt_B: 0.000 \n",
            "(epoch: 21, iters: 1258, time: 1.917, data: 0.003) D_A: 0.120 G_A: 0.741 cycle_A: 0.163 idt_A: 0.000 D_B: 0.379 G_B: 0.467 cycle_B: 0.346 idt_B: 0.001 \n",
            "End of epoch 21 / 60 \t Time Taken: 488 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 22, iters: 24, time: 1.988, data: 0.003) D_A: 0.295 G_A: 0.783 cycle_A: 0.023 idt_A: 0.000 D_B: 0.177 G_B: 0.808 cycle_B: 0.337 idt_B: 0.000 \n",
            "(epoch: 22, iters: 124, time: 1.835, data: 0.003) D_A: 0.166 G_A: 0.691 cycle_A: 0.141 idt_A: 0.022 D_B: 0.244 G_B: 0.251 cycle_B: 0.061 idt_B: 0.000 \n",
            "(epoch: 22, iters: 224, time: 1.893, data: 0.003) D_A: 0.342 G_A: 0.724 cycle_A: 0.156 idt_A: 0.000 D_B: 0.177 G_B: 0.383 cycle_B: 0.010 idt_B: 0.000 \n",
            "(epoch: 22, iters: 324, time: 1.819, data: 0.003) D_A: 0.264 G_A: 0.138 cycle_A: 0.094 idt_A: 0.002 D_B: 0.202 G_B: 0.393 cycle_B: 0.114 idt_B: 0.001 \n",
            "(epoch: 22, iters: 424, time: 1.874, data: 0.003) D_A: 0.146 G_A: 0.483 cycle_A: 0.122 idt_A: 0.119 D_B: 0.136 G_B: 0.355 cycle_B: 0.416 idt_B: 0.000 \n",
            "(epoch: 22, iters: 524, time: 1.832, data: 0.003) D_A: 0.163 G_A: 0.317 cycle_A: 0.030 idt_A: 0.000 D_B: 0.176 G_B: 0.209 cycle_B: 0.427 idt_B: 0.000 \n",
            "(epoch: 22, iters: 624, time: 1.969, data: 0.003) D_A: 0.299 G_A: 0.438 cycle_A: 0.270 idt_A: 0.053 D_B: 0.183 G_B: 0.219 cycle_B: 0.170 idt_B: 0.000 \n",
            "(epoch: 22, iters: 724, time: 1.820, data: 0.003) D_A: 0.210 G_A: 0.241 cycle_A: 0.220 idt_A: 0.000 D_B: 0.175 G_B: 0.251 cycle_B: 0.244 idt_B: 0.000 \n",
            "(epoch: 22, iters: 824, time: 1.829, data: 0.003) D_A: 0.185 G_A: 0.424 cycle_A: 0.031 idt_A: 0.000 D_B: 0.236 G_B: 0.398 cycle_B: 0.185 idt_B: 0.001 \n",
            "(epoch: 22, iters: 924, time: 1.929, data: 0.003) D_A: 0.166 G_A: 0.854 cycle_A: 0.113 idt_A: 0.047 D_B: 0.130 G_B: 0.305 cycle_B: 0.304 idt_B: 0.000 \n",
            "(epoch: 22, iters: 1024, time: 1.901, data: 0.003) D_A: 0.231 G_A: 0.917 cycle_A: 0.146 idt_A: 0.000 D_B: 0.323 G_B: 0.071 cycle_B: 0.099 idt_B: 0.000 \n",
            "(epoch: 22, iters: 1124, time: 1.928, data: 0.003) D_A: 0.107 G_A: 0.426 cycle_A: 0.165 idt_A: 0.000 D_B: 0.219 G_B: 0.226 cycle_B: 0.376 idt_B: 0.003 \n",
            "(epoch: 22, iters: 1224, time: 1.905, data: 0.003) D_A: 0.290 G_A: 0.336 cycle_A: 0.066 idt_A: 0.000 D_B: 0.185 G_B: 0.243 cycle_B: 0.308 idt_B: 0.000 \n",
            "(epoch: 22, iters: 1324, time: 2.027, data: 0.003) D_A: 0.223 G_A: 0.227 cycle_A: 0.154 idt_A: 0.000 D_B: 0.397 G_B: 1.003 cycle_B: 0.308 idt_B: 0.001 \n",
            "saving the latest model (epoch 22, total_iters 20000)\n",
            "End of epoch 22 / 60 \t Time Taken: 491 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 23, iters: 90, time: 2.025, data: 0.002) D_A: 0.133 G_A: 0.331 cycle_A: 0.200 idt_A: 0.000 D_B: 0.333 G_B: 0.233 cycle_B: 0.445 idt_B: 0.000 \n",
            "(epoch: 23, iters: 190, time: 1.999, data: 0.003) D_A: 0.231 G_A: 0.918 cycle_A: 0.099 idt_A: 0.000 D_B: 0.122 G_B: 0.206 cycle_B: 0.148 idt_B: 0.001 \n",
            "(epoch: 23, iters: 290, time: 1.848, data: 0.003) D_A: 0.135 G_A: 0.404 cycle_A: 0.066 idt_A: 0.000 D_B: 0.142 G_B: 0.681 cycle_B: 0.495 idt_B: 0.002 \n",
            "(epoch: 23, iters: 390, time: 1.939, data: 0.003) D_A: 0.152 G_A: 0.074 cycle_A: 0.261 idt_A: 0.000 D_B: 0.362 G_B: 0.644 cycle_B: 0.002 idt_B: 0.001 \n",
            "(epoch: 23, iters: 490, time: 1.911, data: 0.003) D_A: 0.120 G_A: 0.263 cycle_A: 0.237 idt_A: 0.007 D_B: 0.375 G_B: 0.262 cycle_B: 0.240 idt_B: 0.001 \n",
            "(epoch: 23, iters: 590, time: 1.963, data: 0.003) D_A: 0.126 G_A: 0.153 cycle_A: 0.262 idt_A: 0.000 D_B: 0.255 G_B: 0.508 cycle_B: 0.241 idt_B: 0.001 \n",
            "(epoch: 23, iters: 690, time: 1.876, data: 0.003) D_A: 0.255 G_A: 0.248 cycle_A: 0.100 idt_A: 0.000 D_B: 0.225 G_B: 0.313 cycle_B: 0.360 idt_B: 0.000 \n",
            "(epoch: 23, iters: 790, time: 1.945, data: 0.003) D_A: 0.079 G_A: 0.596 cycle_A: 0.089 idt_A: 0.000 D_B: 0.195 G_B: 0.285 cycle_B: 0.414 idt_B: 0.000 \n",
            "(epoch: 23, iters: 890, time: 1.863, data: 0.003) D_A: 0.193 G_A: 0.549 cycle_A: 0.047 idt_A: 0.001 D_B: 0.070 G_B: 0.545 cycle_B: 0.091 idt_B: 0.000 \n",
            "(epoch: 23, iters: 990, time: 1.914, data: 0.004) D_A: 0.104 G_A: 0.403 cycle_A: 0.086 idt_A: 0.000 D_B: 0.152 G_B: 0.271 cycle_B: 0.387 idt_B: 0.000 \n",
            "(epoch: 23, iters: 1090, time: 1.947, data: 0.003) D_A: 0.102 G_A: 0.176 cycle_A: 0.140 idt_A: 0.000 D_B: 0.294 G_B: 0.482 cycle_B: 0.529 idt_B: 0.001 \n",
            "(epoch: 23, iters: 1190, time: 1.969, data: 0.003) D_A: 0.158 G_A: 0.312 cycle_A: 0.264 idt_A: 0.001 D_B: 0.309 G_B: 0.609 cycle_B: 0.394 idt_B: 0.000 \n",
            "(epoch: 23, iters: 1290, time: 1.958, data: 0.003) D_A: 0.052 G_A: 0.278 cycle_A: 0.174 idt_A: 0.000 D_B: 0.251 G_B: 0.987 cycle_B: 0.193 idt_B: 0.000 \n",
            "End of epoch 23 / 60 \t Time Taken: 489 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 24, iters: 56, time: 2.046, data: 0.003) D_A: 0.189 G_A: 0.456 cycle_A: 0.143 idt_A: 0.033 D_B: 0.182 G_B: 0.405 cycle_B: 0.299 idt_B: 0.000 \n",
            "(epoch: 24, iters: 156, time: 2.069, data: 0.003) D_A: 0.105 G_A: 0.369 cycle_A: 0.135 idt_A: 0.000 D_B: 0.273 G_B: 0.312 cycle_B: 0.432 idt_B: 0.002 \n",
            "(epoch: 24, iters: 256, time: 1.882, data: 0.003) D_A: 0.087 G_A: 0.562 cycle_A: 0.078 idt_A: 0.000 D_B: 0.197 G_B: 1.325 cycle_B: 0.001 idt_B: 0.000 \n",
            "(epoch: 24, iters: 356, time: 1.868, data: 0.003) D_A: 0.193 G_A: 0.519 cycle_A: 0.153 idt_A: 0.000 D_B: 0.116 G_B: 0.310 cycle_B: 0.001 idt_B: 0.000 \n",
            "(epoch: 24, iters: 456, time: 1.824, data: 0.004) D_A: 0.117 G_A: 0.529 cycle_A: 0.165 idt_A: 0.000 D_B: 0.316 G_B: 1.283 cycle_B: 0.000 idt_B: 0.000 \n",
            "(epoch: 24, iters: 556, time: 1.887, data: 0.003) D_A: 0.160 G_A: 0.736 cycle_A: 0.069 idt_A: 0.000 D_B: 0.074 G_B: 0.498 cycle_B: 0.002 idt_B: 0.000 \n",
            "(epoch: 24, iters: 656, time: 1.926, data: 0.003) D_A: 0.118 G_A: 0.366 cycle_A: 0.111 idt_A: 0.000 D_B: 0.121 G_B: 0.552 cycle_B: 0.024 idt_B: 0.001 \n",
            "(epoch: 24, iters: 756, time: 1.911, data: 0.003) D_A: 0.123 G_A: 0.319 cycle_A: 0.266 idt_A: 0.000 D_B: 0.276 G_B: 0.169 cycle_B: 0.463 idt_B: 0.027 \n",
            "(epoch: 24, iters: 856, time: 1.942, data: 0.003) D_A: 0.202 G_A: 0.643 cycle_A: 0.157 idt_A: 0.000 D_B: 0.157 G_B: 0.316 cycle_B: 0.302 idt_B: 0.000 \n",
            "(epoch: 24, iters: 956, time: 1.951, data: 0.003) D_A: 0.075 G_A: 0.897 cycle_A: 0.172 idt_A: 0.000 D_B: 0.091 G_B: 0.496 cycle_B: 0.220 idt_B: 0.001 \n",
            "(epoch: 24, iters: 1056, time: 1.968, data: 0.003) D_A: 0.044 G_A: 0.553 cycle_A: 0.120 idt_A: 0.000 D_B: 0.143 G_B: 0.527 cycle_B: 0.485 idt_B: 0.002 \n",
            "(epoch: 24, iters: 1156, time: 1.896, data: 0.003) D_A: 0.223 G_A: 0.208 cycle_A: 0.126 idt_A: 0.002 D_B: 0.216 G_B: 0.263 cycle_B: 0.154 idt_B: 0.000 \n",
            "(epoch: 24, iters: 1256, time: 1.960, data: 0.003) D_A: 0.051 G_A: 0.531 cycle_A: 0.096 idt_A: 0.000 D_B: 0.209 G_B: 0.994 cycle_B: 0.346 idt_B: 0.001 \n",
            "End of epoch 24 / 60 \t Time Taken: 489 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 25, iters: 22, time: 2.143, data: 0.003) D_A: 0.060 G_A: 0.587 cycle_A: 0.161 idt_A: 0.000 D_B: 0.066 G_B: 0.314 cycle_B: 0.406 idt_B: 0.000 \n",
            "(epoch: 25, iters: 122, time: 2.061, data: 0.003) D_A: 0.485 G_A: 0.891 cycle_A: 0.185 idt_A: 0.028 D_B: 0.137 G_B: 0.588 cycle_B: 0.153 idt_B: 0.000 \n",
            "(epoch: 25, iters: 222, time: 1.955, data: 0.003) D_A: 0.135 G_A: 0.581 cycle_A: 0.146 idt_A: 0.002 D_B: 0.138 G_B: 0.720 cycle_B: 0.170 idt_B: 0.000 \n",
            "(epoch: 25, iters: 322, time: 2.008, data: 0.003) D_A: 0.095 G_A: 0.352 cycle_A: 0.042 idt_A: 0.000 D_B: 0.153 G_B: 0.302 cycle_B: 0.356 idt_B: 0.000 \n",
            "(epoch: 25, iters: 422, time: 2.013, data: 0.003) D_A: 0.191 G_A: 0.415 cycle_A: 0.130 idt_A: 0.000 D_B: 0.276 G_B: 0.088 cycle_B: 0.188 idt_B: 0.005 \n",
            "(epoch: 25, iters: 522, time: 1.998, data: 0.003) D_A: 0.101 G_A: 0.398 cycle_A: 0.014 idt_A: 0.000 D_B: 0.242 G_B: 0.563 cycle_B: 0.239 idt_B: 0.000 \n",
            "(epoch: 25, iters: 622, time: 1.938, data: 0.003) D_A: 0.218 G_A: 0.234 cycle_A: 0.407 idt_A: 0.001 D_B: 0.248 G_B: 0.557 cycle_B: 0.178 idt_B: 0.005 \n",
            "(epoch: 25, iters: 722, time: 1.949, data: 0.003) D_A: 0.174 G_A: 0.264 cycle_A: 0.069 idt_A: 0.000 D_B: 0.276 G_B: 0.590 cycle_B: 0.159 idt_B: 0.005 \n",
            "(epoch: 25, iters: 822, time: 2.055, data: 0.003) D_A: 0.131 G_A: 0.818 cycle_A: 0.114 idt_A: 0.000 D_B: 0.178 G_B: 0.334 cycle_B: 0.269 idt_B: 0.000 \n",
            "(epoch: 25, iters: 922, time: 1.980, data: 0.003) D_A: 0.236 G_A: 0.154 cycle_A: 0.147 idt_A: 0.000 D_B: 0.179 G_B: 0.369 cycle_B: 0.082 idt_B: 0.001 \n",
            "(epoch: 25, iters: 1022, time: 2.123, data: 0.003) D_A: 0.165 G_A: 0.307 cycle_A: 0.181 idt_A: 0.000 D_B: 0.152 G_B: 0.543 cycle_B: 0.223 idt_B: 0.001 \n",
            "(epoch: 25, iters: 1122, time: 1.970, data: 0.003) D_A: 0.163 G_A: 0.310 cycle_A: 0.161 idt_A: 0.000 D_B: 0.298 G_B: 0.367 cycle_B: 0.111 idt_B: 0.025 \n",
            "(epoch: 25, iters: 1222, time: 1.959, data: 0.003) D_A: 0.103 G_A: 0.525 cycle_A: 0.031 idt_A: 0.000 D_B: 0.213 G_B: 0.472 cycle_B: 0.536 idt_B: 0.009 \n",
            "(epoch: 25, iters: 1322, time: 2.158, data: 0.003) D_A: 0.166 G_A: 0.609 cycle_A: 0.187 idt_A: 0.000 D_B: 0.242 G_B: 0.285 cycle_B: 0.427 idt_B: 0.000 \n",
            "saving the model at the end of epoch 25, iters 24012\n",
            "End of epoch 25 / 60 \t Time Taken: 496 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 26, iters: 88, time: 2.114, data: 0.003) D_A: 0.282 G_A: 0.254 cycle_A: 0.176 idt_A: 0.001 D_B: 0.120 G_B: 0.535 cycle_B: 0.206 idt_B: 0.000 \n",
            "(epoch: 26, iters: 188, time: 2.069, data: 0.003) D_A: 0.148 G_A: 0.497 cycle_A: 0.122 idt_A: 0.001 D_B: 0.140 G_B: 0.517 cycle_B: 0.254 idt_B: 0.000 \n",
            "(epoch: 26, iters: 288, time: 2.047, data: 0.003) D_A: 0.162 G_A: 1.094 cycle_A: 0.105 idt_A: 0.000 D_B: 0.150 G_B: 0.514 cycle_B: 0.295 idt_B: 0.000 \n",
            "(epoch: 26, iters: 388, time: 2.002, data: 0.003) D_A: 0.128 G_A: 0.809 cycle_A: 0.092 idt_A: 0.000 D_B: 0.228 G_B: 0.457 cycle_B: 0.202 idt_B: 0.000 \n",
            "(epoch: 26, iters: 488, time: 2.059, data: 0.003) D_A: 0.178 G_A: 0.361 cycle_A: 0.002 idt_A: 0.003 D_B: 0.284 G_B: 0.514 cycle_B: 0.092 idt_B: 0.000 \n",
            "(epoch: 26, iters: 588, time: 2.018, data: 0.003) D_A: 0.108 G_A: 0.661 cycle_A: 0.066 idt_A: 0.000 D_B: 0.176 G_B: 0.836 cycle_B: 0.295 idt_B: 0.000 \n",
            "(epoch: 26, iters: 688, time: 1.974, data: 0.003) D_A: 0.188 G_A: 0.736 cycle_A: 0.016 idt_A: 0.000 D_B: 0.175 G_B: 0.548 cycle_B: 0.186 idt_B: 0.000 \n",
            "(epoch: 26, iters: 788, time: 1.987, data: 0.003) D_A: 0.247 G_A: 0.402 cycle_A: 0.153 idt_A: 0.000 D_B: 0.295 G_B: 0.299 cycle_B: 0.158 idt_B: 0.000 \n",
            "(epoch: 26, iters: 888, time: 2.018, data: 0.003) D_A: 0.373 G_A: 1.002 cycle_A: 0.100 idt_A: 0.000 D_B: 0.199 G_B: 0.152 cycle_B: 0.142 idt_B: 0.000 \n",
            "(epoch: 26, iters: 988, time: 2.053, data: 0.003) D_A: 0.161 G_A: 0.446 cycle_A: 0.103 idt_A: 0.000 D_B: 0.199 G_B: 0.211 cycle_B: 0.340 idt_B: 0.000 \n",
            "saving the latest model (epoch 26, total_iters 25000)\n",
            "(epoch: 26, iters: 1088, time: 2.088, data: 0.003) D_A: 0.057 G_A: 0.566 cycle_A: 0.081 idt_A: 0.000 D_B: 0.243 G_B: 0.730 cycle_B: 0.288 idt_B: 0.001 \n",
            "(epoch: 26, iters: 1188, time: 2.074, data: 0.003) D_A: 0.229 G_A: 0.633 cycle_A: 0.117 idt_A: 0.000 D_B: 0.230 G_B: 0.286 cycle_B: 0.148 idt_B: 0.003 \n",
            "(epoch: 26, iters: 1288, time: 2.079, data: 0.003) D_A: 0.135 G_A: 0.617 cycle_A: 0.009 idt_A: 0.000 D_B: 0.200 G_B: 0.258 cycle_B: 0.155 idt_B: 0.000 \n",
            "End of epoch 26 / 60 \t Time Taken: 492 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 27, iters: 54, time: 2.113, data: 0.003) D_A: 0.125 G_A: 0.689 cycle_A: 0.074 idt_A: 0.000 D_B: 0.298 G_B: 0.702 cycle_B: 0.470 idt_B: 0.000 \n",
            "(epoch: 27, iters: 154, time: 2.120, data: 0.003) D_A: 0.070 G_A: 0.676 cycle_A: 0.055 idt_A: 0.000 D_B: 0.141 G_B: 0.338 cycle_B: 0.430 idt_B: 0.000 \n",
            "(epoch: 27, iters: 254, time: 2.043, data: 0.004) D_A: 0.145 G_A: 0.377 cycle_A: 0.254 idt_A: 0.001 D_B: 0.221 G_B: 0.651 cycle_B: 0.146 idt_B: 0.000 \n",
            "(epoch: 27, iters: 354, time: 2.011, data: 0.003) D_A: 0.285 G_A: 0.246 cycle_A: 0.151 idt_A: 0.000 D_B: 0.270 G_B: 0.127 cycle_B: 0.118 idt_B: 0.000 \n",
            "(epoch: 27, iters: 454, time: 2.072, data: 0.003) D_A: 0.223 G_A: 0.548 cycle_A: 0.473 idt_A: 0.008 D_B: 0.238 G_B: 0.319 cycle_B: 0.198 idt_B: 0.001 \n",
            "(epoch: 27, iters: 554, time: 2.076, data: 0.003) D_A: 0.096 G_A: 0.474 cycle_A: 0.751 idt_A: 0.000 D_B: 0.121 G_B: 0.772 cycle_B: 0.180 idt_B: 0.000 \n",
            "(epoch: 27, iters: 654, time: 2.050, data: 0.003) D_A: 0.308 G_A: 0.174 cycle_A: 0.103 idt_A: 0.000 D_B: 0.351 G_B: 0.168 cycle_B: 0.262 idt_B: 0.005 \n",
            "(epoch: 27, iters: 754, time: 1.960, data: 0.003) D_A: 0.247 G_A: 0.631 cycle_A: 0.038 idt_A: 0.000 D_B: 0.220 G_B: 0.618 cycle_B: 0.231 idt_B: 0.001 \n",
            "(epoch: 27, iters: 854, time: 1.996, data: 0.003) D_A: 0.195 G_A: 0.438 cycle_A: 0.066 idt_A: 0.000 D_B: 0.233 G_B: 0.569 cycle_B: 0.346 idt_B: 0.000 \n",
            "(epoch: 27, iters: 954, time: 2.148, data: 0.003) D_A: 0.117 G_A: 0.718 cycle_A: 0.156 idt_A: 0.041 D_B: 0.282 G_B: 0.266 cycle_B: 0.462 idt_B: 0.000 \n",
            "(epoch: 27, iters: 1054, time: 1.967, data: 0.004) D_A: 0.220 G_A: 0.280 cycle_A: 0.146 idt_A: 0.000 D_B: 0.307 G_B: 0.157 cycle_B: 0.196 idt_B: 0.000 \n",
            "(epoch: 27, iters: 1154, time: 2.108, data: 0.003) D_A: 0.146 G_A: 0.621 cycle_A: 0.064 idt_A: 0.000 D_B: 0.161 G_B: 0.280 cycle_B: 0.184 idt_B: 0.000 \n",
            "(epoch: 27, iters: 1254, time: 2.118, data: 0.003) D_A: 0.164 G_A: 0.674 cycle_A: 0.093 idt_A: 0.000 D_B: 0.183 G_B: 0.293 cycle_B: 0.278 idt_B: 0.000 \n",
            "End of epoch 27 / 60 \t Time Taken: 492 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 28, iters: 20, time: 2.210, data: 0.003) D_A: 0.122 G_A: 0.426 cycle_A: 0.116 idt_A: 0.000 D_B: 0.227 G_B: 0.641 cycle_B: 0.319 idt_B: 0.000 \n",
            "(epoch: 28, iters: 120, time: 2.207, data: 0.003) D_A: 0.128 G_A: 0.587 cycle_A: 0.173 idt_A: 0.014 D_B: 0.287 G_B: 0.158 cycle_B: 0.178 idt_B: 0.000 \n",
            "(epoch: 28, iters: 220, time: 2.076, data: 0.003) D_A: 0.236 G_A: 0.541 cycle_A: 0.137 idt_A: 0.000 D_B: 0.160 G_B: 0.388 cycle_B: 0.102 idt_B: 0.000 \n",
            "(epoch: 28, iters: 320, time: 2.011, data: 0.004) D_A: 0.201 G_A: 0.298 cycle_A: 0.221 idt_A: 0.000 D_B: 0.319 G_B: 0.393 cycle_B: 0.264 idt_B: 0.004 \n",
            "(epoch: 28, iters: 420, time: 2.130, data: 0.003) D_A: 0.214 G_A: 0.524 cycle_A: 0.209 idt_A: 0.000 D_B: 0.126 G_B: 0.383 cycle_B: 0.101 idt_B: 0.000 \n",
            "(epoch: 28, iters: 520, time: 2.030, data: 0.003) D_A: 0.321 G_A: 0.083 cycle_A: 0.110 idt_A: 0.000 D_B: 0.494 G_B: 0.952 cycle_B: 0.383 idt_B: 0.002 \n",
            "(epoch: 28, iters: 620, time: 2.122, data: 0.003) D_A: 0.191 G_A: 0.644 cycle_A: 0.120 idt_A: 0.143 D_B: 0.179 G_B: 0.310 cycle_B: 0.223 idt_B: 0.000 \n",
            "(epoch: 28, iters: 720, time: 2.062, data: 0.003) D_A: 0.086 G_A: 0.960 cycle_A: 0.074 idt_A: 0.000 D_B: 0.234 G_B: 0.699 cycle_B: 0.307 idt_B: 0.000 \n",
            "(epoch: 28, iters: 820, time: 2.215, data: 0.002) D_A: 0.101 G_A: 0.505 cycle_A: 0.202 idt_A: 0.010 D_B: 0.114 G_B: 0.259 cycle_B: 0.592 idt_B: 0.001 \n",
            "(epoch: 28, iters: 920, time: 2.007, data: 0.003) D_A: 0.053 G_A: 0.628 cycle_A: 0.056 idt_A: 0.000 D_B: 0.141 G_B: 0.403 cycle_B: 0.267 idt_B: 0.000 \n",
            "(epoch: 28, iters: 1020, time: 2.143, data: 0.003) D_A: 0.151 G_A: 0.289 cycle_A: 0.196 idt_A: 0.000 D_B: 0.311 G_B: 0.254 cycle_B: 0.384 idt_B: 0.000 \n",
            "(epoch: 28, iters: 1120, time: 2.046, data: 0.003) D_A: 0.607 G_A: 1.198 cycle_A: 0.324 idt_A: 0.010 D_B: 0.198 G_B: 0.209 cycle_B: 0.068 idt_B: 0.000 \n",
            "(epoch: 28, iters: 1220, time: 2.112, data: 0.003) D_A: 0.384 G_A: 0.661 cycle_A: 0.282 idt_A: 0.100 D_B: 0.190 G_B: 0.150 cycle_B: 0.072 idt_B: 0.000 \n",
            "(epoch: 28, iters: 1320, time: 2.110, data: 0.003) D_A: 0.282 G_A: 0.116 cycle_A: 0.011 idt_A: 0.000 D_B: 0.312 G_B: 0.671 cycle_B: 0.269 idt_B: 0.000 \n",
            "End of epoch 28 / 60 \t Time Taken: 496 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 29, iters: 86, time: 2.271, data: 0.003) D_A: 0.230 G_A: 0.188 cycle_A: 0.242 idt_A: 0.000 D_B: 0.222 G_B: 0.297 cycle_B: 0.245 idt_B: 0.001 \n",
            "(epoch: 29, iters: 186, time: 2.130, data: 0.003) D_A: 0.160 G_A: 0.583 cycle_A: 0.227 idt_A: 0.002 D_B: 0.220 G_B: 0.636 cycle_B: 0.317 idt_B: 0.000 \n",
            "(epoch: 29, iters: 286, time: 2.183, data: 0.003) D_A: 0.080 G_A: 0.660 cycle_A: 0.177 idt_A: 0.000 D_B: 0.174 G_B: 0.479 cycle_B: 0.370 idt_B: 0.000 \n",
            "(epoch: 29, iters: 386, time: 2.112, data: 0.003) D_A: 0.135 G_A: 0.651 cycle_A: 0.023 idt_A: 0.000 D_B: 0.112 G_B: 0.716 cycle_B: 0.226 idt_B: 0.000 \n",
            "(epoch: 29, iters: 486, time: 2.129, data: 0.003) D_A: 0.122 G_A: 0.478 cycle_A: 0.070 idt_A: 0.001 D_B: 0.197 G_B: 0.359 cycle_B: 0.073 idt_B: 0.003 \n",
            "(epoch: 29, iters: 586, time: 2.147, data: 0.003) D_A: 0.167 G_A: 0.737 cycle_A: 0.145 idt_A: 0.015 D_B: 0.049 G_B: 1.021 cycle_B: 0.198 idt_B: 0.000 \n",
            "(epoch: 29, iters: 686, time: 2.138, data: 0.003) D_A: 0.182 G_A: 0.622 cycle_A: 0.010 idt_A: 0.000 D_B: 0.321 G_B: 0.646 cycle_B: 0.291 idt_B: 0.000 \n",
            "(epoch: 29, iters: 786, time: 2.044, data: 0.003) D_A: 0.211 G_A: 0.715 cycle_A: 0.181 idt_A: 0.000 D_B: 0.087 G_B: 0.449 cycle_B: 0.172 idt_B: 0.000 \n",
            "(epoch: 29, iters: 886, time: 2.136, data: 0.002) D_A: 0.188 G_A: 0.237 cycle_A: 0.196 idt_A: 0.000 D_B: 0.276 G_B: 0.205 cycle_B: 0.193 idt_B: 0.000 \n",
            "(epoch: 29, iters: 986, time: 2.117, data: 0.003) D_A: 0.179 G_A: 0.277 cycle_A: 0.269 idt_A: 0.000 D_B: 0.295 G_B: 0.352 cycle_B: 0.272 idt_B: 0.001 \n",
            "(epoch: 29, iters: 1086, time: 2.125, data: 0.002) D_A: 0.204 G_A: 0.807 cycle_A: 0.216 idt_A: 0.002 D_B: 0.140 G_B: 0.450 cycle_B: 0.107 idt_B: 0.000 \n",
            "(epoch: 29, iters: 1186, time: 2.133, data: 0.003) D_A: 0.195 G_A: 0.223 cycle_A: 0.171 idt_A: 0.000 D_B: 0.266 G_B: 0.544 cycle_B: 0.545 idt_B: 0.000 \n",
            "(epoch: 29, iters: 1286, time: 2.128, data: 0.003) D_A: 0.088 G_A: 1.267 cycle_A: 0.187 idt_A: 0.000 D_B: 0.102 G_B: 0.465 cycle_B: 0.425 idt_B: 0.000 \n",
            "End of epoch 29 / 60 \t Time Taken: 494 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 30, iters: 52, time: 2.232, data: 0.003) D_A: 0.126 G_A: 0.517 cycle_A: 0.179 idt_A: 0.000 D_B: 0.179 G_B: 0.328 cycle_B: 0.268 idt_B: 0.002 \n",
            "(epoch: 30, iters: 152, time: 2.177, data: 0.003) D_A: 0.125 G_A: 0.187 cycle_A: 0.166 idt_A: 0.000 D_B: 0.306 G_B: 0.948 cycle_B: 0.419 idt_B: 0.000 \n",
            "(epoch: 30, iters: 252, time: 2.112, data: 0.003) D_A: 0.164 G_A: 0.839 cycle_A: 0.013 idt_A: 0.000 D_B: 0.068 G_B: 0.736 cycle_B: 0.108 idt_B: 0.000 \n",
            "(epoch: 30, iters: 352, time: 2.224, data: 0.003) D_A: 0.201 G_A: 0.598 cycle_A: 0.190 idt_A: 0.000 D_B: 0.280 G_B: 0.160 cycle_B: 0.254 idt_B: 0.004 \n",
            "(epoch: 30, iters: 452, time: 2.205, data: 0.003) D_A: 0.279 G_A: 0.402 cycle_A: 0.117 idt_A: 0.000 D_B: 0.135 G_B: 0.215 cycle_B: 0.243 idt_B: 0.000 \n",
            "(epoch: 30, iters: 552, time: 2.199, data: 0.003) D_A: 0.212 G_A: 0.637 cycle_A: 0.224 idt_A: 0.000 D_B: 0.225 G_B: 0.400 cycle_B: 0.125 idt_B: 0.000 \n",
            "(epoch: 30, iters: 652, time: 2.079, data: 0.003) D_A: 0.368 G_A: 0.332 cycle_A: 0.132 idt_A: 0.000 D_B: 0.136 G_B: 0.152 cycle_B: 0.098 idt_B: 0.001 \n",
            "saving the latest model (epoch 30, total_iters 30000)\n",
            "(epoch: 30, iters: 752, time: 2.166, data: 0.002) D_A: 0.107 G_A: 0.372 cycle_A: 0.100 idt_A: 0.000 D_B: 0.218 G_B: 0.441 cycle_B: 0.282 idt_B: 0.000 \n",
            "(epoch: 30, iters: 852, time: 2.280, data: 0.003) D_A: 0.077 G_A: 1.021 cycle_A: 0.195 idt_A: 0.000 D_B: 0.149 G_B: 0.236 cycle_B: 0.301 idt_B: 0.000 \n",
            "(epoch: 30, iters: 952, time: 2.127, data: 0.003) D_A: 0.498 G_A: 0.195 cycle_A: 0.115 idt_A: 0.000 D_B: 0.300 G_B: 0.411 cycle_B: 0.190 idt_B: 0.000 \n",
            "(epoch: 30, iters: 1052, time: 2.278, data: 0.003) D_A: 0.152 G_A: 0.550 cycle_A: 0.090 idt_A: 0.057 D_B: 0.241 G_B: 0.159 cycle_B: 0.233 idt_B: 0.000 \n",
            "(epoch: 30, iters: 1152, time: 2.242, data: 0.003) D_A: 0.121 G_A: 1.155 cycle_A: 0.046 idt_A: 0.000 D_B: 0.153 G_B: 0.321 cycle_B: 0.349 idt_B: 0.000 \n",
            "(epoch: 30, iters: 1252, time: 2.096, data: 0.003) D_A: 0.231 G_A: 0.531 cycle_A: 0.180 idt_A: 0.000 D_B: 0.143 G_B: 0.371 cycle_B: 0.207 idt_B: 0.000 \n",
            "saving the model at the end of epoch 30, iters 30682\n",
            "End of epoch 30 / 60 \t Time Taken: 500 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 31, iters: 18, time: 2.635, data: 0.003) D_A: 0.080 G_A: 0.329 cycle_A: 0.106 idt_A: 0.000 D_B: 0.224 G_B: 0.697 cycle_B: 0.319 idt_B: 0.004 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hcc5aaNUxz0w",
        "colab_type": "text"
      },
      "source": [
        "**Test**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "722H-AxFvXRs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f84d69f1-14bd-4093-92ab-ce329bf19f39"
      },
      "source": [
        "!sh ./scripts/test_attentiongan.sh"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+ python test.py --dataroot ./datasets/horse2zebra --name horse2zebra_attentiongan --model attention_gan --dataset_mode unaligned --norm instance --phase test --no_dropout --load_size 256 --crop_size 256 --batch_size 1 --gpu_ids 0 --num_test 1000000000 --saveDisk\n",
            "----------------- Options ---------------\n",
            "             aspect_ratio: 1.0                           \n",
            "               batch_size: 1                             \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "                crop_size: 256                           \n",
            "                 dataroot: ./datasets/horse2zebra        \t[default: None]\n",
            "             dataset_mode: unaligned                     \n",
            "                direction: AtoB                          \n",
            "          display_winsize: 256                           \n",
            "                    epoch: latest                        \n",
            "                     eval: False                         \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: False                         \t[default: None]\n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 256                           \n",
            "         max_dataset_size: inf                           \n",
            "                    model: attention_gan                 \t[default: test]\n",
            "               n_layers_D: 3                             \n",
            "                     name: horse2zebra_attentiongan      \t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: resnet_9blocks                \n",
            "                      ngf: 64                            \n",
            "               no_dropout: True                          \n",
            "                  no_flip: False                         \n",
            "                     norm: instance                      \n",
            "                    ntest: inf                           \n",
            "                 num_test: 1000000000                    \t[default: 50]\n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: test                          \n",
            "               preprocess: resize_and_crop               \n",
            "              results_dir: ./results/                    \n",
            "                 saveDisk: True                          \t[default: False]\n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "                  verbose: False                         \n",
            "----------------- End -------------------\n",
            "dataset [UnalignedDataset] was created\n",
            "initialize network with normal\n",
            "initialize network with normal\n",
            "model [AttentionGANModel] was created\n",
            "loading the model from ./checkpoints/horse2zebra_attentiongan/latest_net_G_A.pth\n",
            "loading the model from ./checkpoints/horse2zebra_attentiongan/latest_net_G_B.pth\n",
            "---------- Networks initialized -------------\n",
            "[Network G_A] Total number of parameters : 11.823 M\n",
            "[Network G_B] Total number of parameters : 11.823 M\n",
            "-----------------------------------------------\n",
            "processing (0000)-th image... ['./datasets/horse2zebra/testA/n02381460_1000.jpg']\n",
            "processing (0005)-th image... ['./datasets/horse2zebra/testA/n02381460_1110.jpg']\n",
            "processing (0010)-th image... ['./datasets/horse2zebra/testA/n02381460_1260.jpg']\n",
            "processing (0015)-th image... ['./datasets/horse2zebra/testA/n02381460_1420.jpg']\n",
            "processing (0020)-th image... ['./datasets/horse2zebra/testA/n02381460_1690.jpg']\n",
            "processing (0025)-th image... ['./datasets/horse2zebra/testA/n02381460_1830.jpg']\n",
            "processing (0030)-th image... ['./datasets/horse2zebra/testA/n02381460_2050.jpg']\n",
            "processing (0035)-th image... ['./datasets/horse2zebra/testA/n02381460_2460.jpg']\n",
            "processing (0040)-th image... ['./datasets/horse2zebra/testA/n02381460_2870.jpg']\n",
            "processing (0045)-th image... ['./datasets/horse2zebra/testA/n02381460_3040.jpg']\n",
            "processing (0050)-th image... ['./datasets/horse2zebra/testA/n02381460_360.jpg']\n",
            "processing (0055)-th image... ['./datasets/horse2zebra/testA/n02381460_4110.jpg']\n",
            "processing (0060)-th image... ['./datasets/horse2zebra/testA/n02381460_4310.jpg']\n",
            "processing (0065)-th image... ['./datasets/horse2zebra/testA/n02381460_4430.jpg']\n",
            "processing (0070)-th image... ['./datasets/horse2zebra/testA/n02381460_4630.jpg']\n",
            "processing (0075)-th image... ['./datasets/horse2zebra/testA/n02381460_4740.jpg']\n",
            "processing (0080)-th image... ['./datasets/horse2zebra/testA/n02381460_500.jpg']\n",
            "processing (0085)-th image... ['./datasets/horse2zebra/testA/n02381460_5670.jpg']\n",
            "processing (0090)-th image... ['./datasets/horse2zebra/testA/n02381460_640.jpg']\n",
            "processing (0095)-th image... ['./datasets/horse2zebra/testA/n02381460_690.jpg']\n",
            "processing (0100)-th image... ['./datasets/horse2zebra/testA/n02381460_7190.jpg']\n",
            "processing (0105)-th image... ['./datasets/horse2zebra/testA/n02381460_7500.jpg']\n",
            "processing (0110)-th image... ['./datasets/horse2zebra/testA/n02381460_7970.jpg']\n",
            "processing (0115)-th image... ['./datasets/horse2zebra/testA/n02381460_900.jpg']\n",
            "processing (0120)-th image... ['./datasets/horse2zebra/testA/n02381460_1000.jpg']\n",
            "processing (0125)-th image... ['./datasets/horse2zebra/testA/n02381460_1110.jpg']\n",
            "processing (0130)-th image... ['./datasets/horse2zebra/testA/n02381460_1260.jpg']\n",
            "processing (0135)-th image... ['./datasets/horse2zebra/testA/n02381460_1420.jpg']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0WkpcuevXjM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uaX1th3ivXpc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "boBL7RuZvXgG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NfsV8tu0vXc-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJgnReDQvXaB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Atf4A2zvXN7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMLeGrHOvXLI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xeYFOURivXI_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TaMnwgS1vXGQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6BJKkwlmSHc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AB_vezxUmSDo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "outputId": "2af2216b-d406-40d1-c06a-9b94d7581a6f"
      },
      "source": [
        "!/opt/bin/nvidia-smi\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thu Jul 16 10:02:37 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 418.67       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P8    28W / 149W |     11MiB / 11441MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85gYCLnlE482",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "c9755896-360a-4ad0-9fd2-86c6c803ea91"
      },
      "source": [
        "!ps -aux|grep python\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root          23  0.3  0.7 412236 103088 ?       Sl   09:48   0:02 /usr/bin/python2 /usr/local/bin/jupyter-notebook --ip=\"172.28.0.2\" --port=9000 --FileContentsManager.root_dir=\"/\" --MappingKernelManager.root_dir=\"/content\"\n",
            "root         463  0.4  2.0 39904900 276836 ?     Ssl  09:54   0:02 /usr/bin/python3 -m ipykernel_launcher -f /root/.local/share/jupyter/runtime/kernel-13e1ef72-1c77-4b29-9948-d39b73a19763.json\n",
            "root         605  0.0  0.0  39192  6364 ?        S    10:03   0:00 /bin/bash -c ps -aux|grep python\n",
            "root         607  0.0  0.0  38568  5548 ?        S    10:03   0:00 grep python\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5_v4ylQE45q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "torch.cuda.empty_cache()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qa2eUPI1H6Wo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "7ae7b534-40ef-4a11-d7fa-13924d100ddb"
      },
      "source": [
        "import torch\n",
        "train_on_gpu = torch.cuda.is_available()\n",
        "\n",
        "if not train_on_gpu:\n",
        "  print(\"1\")\n",
        "\n",
        "else:\n",
        "  print(\"training on gpu\")\n",
        "\n",
        "#print(torch.cuda.current_device())\n",
        "print(torch.cuda.device(0))\n",
        "print(torch.cuda.device_count())\n",
        "print(torch.cuda.get_device_name(0))\n",
        "print(torch.cuda.is_available())\n",
        "print(torch.cuda.current_device())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training on gpu\n",
            "<torch.cuda.device object at 0x7fb3a0f98c88>\n",
            "1\n",
            "Tesla K80\n",
            "True\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_pIh_S1fLfxr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}