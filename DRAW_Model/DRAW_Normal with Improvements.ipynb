{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.14.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# for this tutorial use tf version 2.0.0-rc0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagio is used for gif generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.0.2; however, version 20.1.1 is available.\n",
      "You should consider upgrading via the 'c:\\users\\samya\\anaconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install -q imageio\n",
    "## imageio is used here for gif generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import imageio \n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import PIL\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.python.keras.layers import Flatten,Dropout,Conv2DTranspose,Reshape, Dense, BatchNormalization,LeakyReLU,Conv2D,ReLU\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "\n",
    "import time \n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (_, _) = tf.keras.datasets.mnist.load_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Loading of Data and Normalizing it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32')\n",
    "train_images = (train_images - 127.5) / 127.5 # Normalize the images to [-1, 1]\n",
    "\n",
    "BUFFER_SIZE = 60000\n",
    "BATCH_SIZE = 32\n",
    "    \n",
    "# Batch and shuffle the data\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generator model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_generator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(Dense(7*7*256, use_bias=False, input_shape=(256,)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(ReLU())\n",
    " ## assert is used only for checking if the value is correct or not\n",
    "    model.add(Reshape((7, 7, 256)))\n",
    "    assert model.output_shape == (None, 7, 7, 256) # Note: None is the batch size\n",
    "##  Transposed convolution layer (sometimes called Deconvolution).\n",
    "##  Deconv is also used for construction of images.\n",
    "\n",
    "    model.add(Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n",
    "    assert model.output_shape == (None, 7, 7, 128)\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(ReLU())\n",
    "\n",
    "    model.add(Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
    "    assert model.output_shape == (None, 14, 14, 64)\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(ReLU())\n",
    "\n",
    "    model.add(Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
    "    assert model.output_shape == (None, 28, 28, 1)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0526 18:32:37.559134 12156 deprecation.py:506] From C:\\Users\\samya\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "\n",
    "generator = make_generator_model()\n",
    "\n",
    "noise = tf.random.normal([1, 256])\n",
    "generated_image = generator(noise, training=False)\n",
    "\n",
    "#plt.imshow(generated_image[0, :, :, 0], cmap='gray')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discriminator Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_discriminator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(Conv2D(64, (5, 5), strides=(2, 2), padding='same',\n",
    "                                     input_shape=[28, 28, 1]))\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"sequential_1/dense_1/BiasAdd:0\", shape=(1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "discriminator = make_discriminator_model()\n",
    "decision = discriminator(generated_image)\n",
    "print (decision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
    "                                 discriminator_optimizer=discriminator_optimizer,\n",
    "                                 generator=generator,\n",
    "                                 discriminator=discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "noise_dim = 256\n",
    "num_examples_to_generate = 16\n",
    "\n",
    "# We will reuse this seed overtime (so it's easier)\n",
    "# to visualize progress in the animated GIF)\n",
    "seed = tf.random.normal([num_examples_to_generate, noise_dim])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice the use of `tf.function`\n",
    "# This annotation causes the function to be \"compiled\".\n",
    "@tf.function\n",
    "def train_step(images):\n",
    "    \n",
    "    noise = tf.random.normal([BATCH_SIZE, noise_dim])\n",
    "\n",
    "##    Gradient Tape tracks the automatic differentiation that occurs in a TF model.\n",
    "    \n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        \n",
    "        generated_images = generator(noise, training=True)\n",
    "\n",
    "        real_output = discriminator(images, training=True)\n",
    "        fake_output = discriminator(generated_images, training=True)\n",
    "\n",
    "        gen_loss = generator_loss(fake_output)\n",
    "        disc_loss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataset, epochs):\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        start = time.time()\n",
    "\n",
    "        for image_batch in dataset:\n",
    "            train_step(image_batch)\n",
    "\n",
    "    # Produce images for the GIF as we go\n",
    "        display.clear_output(wait=True)\n",
    "        generate_and_save_images(generator,\n",
    "                             epoch + 1,\n",
    "                             seed)\n",
    "\n",
    "    # Save the model every 5 epochs\n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            \n",
    "            checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "\n",
    "        print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
    "\n",
    "  # Generate after the final epoch\n",
    "    display.clear_output(wait=True)\n",
    "    generate_and_save_images(generator,\n",
    "                           epochs,\n",
    "                           seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_save_images(model, epoch, test_input):\n",
    "    \n",
    "  # Notice `training` is set to False.\n",
    "  # This is so all layers run in inference mode (batchnorm).\n",
    "    predictions = model(test_input, training=False)\n",
    "\n",
    "    fig = plt.figure(figsize=(4,4))\n",
    "\n",
    "    for i in range(predictions.shape[0]):\n",
    "        \n",
    "        plt.subplot(4, 4, i+1)\n",
    "        plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0526 18:33:05.136817 12156 deprecation.py:323] From C:\\Users\\samya\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-d152560ca122>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-18-cffb0d91fc54>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(dataset, epochs)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mimage_batch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m             \u001b[0mtrain_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;31m# Produce images for the GIF as we go\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    404\u001b[0m       \u001b[1;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    405\u001b[0m       \u001b[1;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 406\u001b[1;33m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    407\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    408\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1322\u001b[0m     \u001b[1;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1323\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1324\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1325\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1326\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m    576\u001b[0m     \"\"\"\n\u001b[0;32m    577\u001b[0m     return self._call_flat(\n\u001b[1;32m--> 578\u001b[1;33m         (t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[0m\u001b[0;32m    579\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m    580\u001b[0m                            resource_variable_ops.ResourceVariable))))\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    658\u001b[0m     \u001b[1;31m# Only need to override the gradient in graph mode and when we have outputs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    659\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 660\u001b[1;33m       \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    661\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    662\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_register_gradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args)\u001b[0m\n\u001b[0;32m    447\u001b[0m               \u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    448\u001b[0m               \u001b[0mconfig\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 449\u001b[1;33m               executor_type=executor_type)\n\u001b[0m\u001b[0;32m    450\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    451\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\functional_ops.py\u001b[0m in \u001b[0;36mpartitioned_call\u001b[1;34m(args, f, tout, executing_eagerly, config, executor_type)\u001b[0m\n\u001b[0;32m    884\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    885\u001b[0m   \u001b[0mgraph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 886\u001b[1;33m   \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_to_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    887\u001b[0m   \u001b[0mop_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"StatefulPartitionedCall\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstateful_ops\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"PartitionedCall\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m   op = graph.create_op(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36madd_to_graph\u001b[1;34m(self, g)\u001b[0m\n\u001b[0;32m    385\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_functions\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 387\u001b[1;33m         \u001b[0mg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_add_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    388\u001b[0m       \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_functions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    389\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_functions\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_add_function\u001b[1;34m(self, function)\u001b[0m\n\u001b[0;32m   3518\u001b[0m     gradient = (\n\u001b[0;32m   3519\u001b[0m         function._grad_func._c_func.func if function._grad_func else None)\n\u001b[1;32m-> 3520\u001b[1;33m     \u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GraphCopyFunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_c_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_c_func\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3521\u001b[0m     \u001b[1;31m# pylint: enable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3522\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(train_dataset, EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x2c4adb926a0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image(epoch_no):\n",
    "    \n",
    "    return PIL.Image.open('image_at_epoch_{:04d}.png'.format(epoch_no))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=288x288 at 0x2C4ADB895C0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display_image(EPOCHS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "anim_file = 'sam.gif'\n",
    "\n",
    "with imageio.get_writer(anim_file, mode='I') as writer:\n",
    "    \n",
    "    \n",
    "    filenames = glob.glob('image*.png')\n",
    "    filenames = sorted(filenames)\n",
    "    last = -1\n",
    "    for i,filename in enumerate(filenames):\n",
    "        \n",
    "        frame = 2*(i**0.5)\n",
    "        if round(frame) > round(last):\n",
    "            \n",
    "            last = frame\n",
    "        else:\n",
    "            continue\n",
    "        image = imageio.imread(filename)\n",
    "        writer.append_data(image)\n",
    "    image = imageio.imread(filename)\n",
    "    writer.append_data(image)\n",
    "\n",
    "import IPython\n",
    "if IPython.version_info > (6,2,0,''):\n",
    "    \n",
    "    display.Image(filename=anim_file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}